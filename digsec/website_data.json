[
    {
        "abstract": "Remote state preparation with verifiability (RSPV) is an important quantum cryptographic primitive. In this primitive, a client would like to prepare a quantum state (sampled or chosen from a state family) on the server side, such that ideally the client knows its full description, while the server holds and only holds the state itself. In this work we make several contributions on its formulations, constructions and applications. In more detail:\r\n\r\n- We first work on the definitions and abstract properties of the RSPV problem. We select and compare different variants of definitions, and study their basic properties (like composability and amplification).\r\n\r\n- We also study a closely related question of how to certify the server's operations (instead of solely the states). We introduce a new notion named remote operator application with verifiability (ROAV). We compare this notion with related existing definitions, study its abstract properties and leave its concrete constructions for further works.\r\n\r\n- Building on the abstract properties and existing results, we construct a series of new RSPV protocols. Our constructions not only simplify existing results but also cover new state families, for example, states in the form of $\\frac{1}{\\sqrt{2}}(|0\\rangle|x_0\\rangle+|1\\rangle|x_1\\rangle)$. All these constructions rely only on the existence of weak NTCF, without additional requirements like the adaptive hardcore bit property.\r\n\r\n- As a further application, we show that the classical verification of quantum computations (CVQC) problem could be constructed from assumptions on group actions. This is achieved by combining our results on RSPV with group-action-based instantiation of weak NTCF, and then with the quantum-gadget-assisted quantum verification protocol.",
        "authors": [
            "Jiayu Zhang"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-06 10:48:17",
        "name": "2023/1490",
        "pdffile": "2023/1490.pdf",
        "pid": 1490,
        "title": "Formulations and Constructions of Remote State Preparation with Verifiability, with Applications",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "Security proofs for cryptographic primitives typically assume operations are executed in the correct sequence; however, insecure implementations or software-level attacks can disrupt control flows, potentially invalidating these guarantees. To address this issue, we introduce a new security notion, IND-CFA, which formalizes decryption\r\nsecurity in the presence of adversarially controlled execution flows. Using this notion, we investigate the control flows under which a cryptographic scheme remains secure, providing insights into secure implementation practices. We revisit the Encrypt-then-MAC paradigm, underscoring the crucial role of operation sequencing in ensuring the\r\nsecurity of authenticated encryption schemes built using this method. Additionally, we provide a detailed analysis of the Encode-then-Encipher (EtE) paradigm, a widely adopted approach for constructing robust AE schemes, revealing its vulnerability to adversarial control flows that can enable attackers to infer low-entropy values in the\r\npresence of multiple failure conditions.",
        "authors": [
            "Ganyuan Cao"
        ],
        "category": "Secret-key cryptography",
        "lastmodified": "2024-11-06 07:38:49",
        "name": "2024/598",
        "pdffile": "2024/598.pdf",
        "pid": 598,
        "title": "Decryption Indistinguishability under Chosen Control Flow",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "HQC is a code-based key encapsulation mechanism (KEM)\r\nthat was selected to move to the fourth round of the NIST post-quantum\r\nstandardization process. While this scheme was previously targeted by\r\nside-channel assisted chosen-ciphertext attacks for key recovery, all these attacks have relied on malformed ciphertexts for key recovery. Thus, all these attacks can be easily prevented by deploying a detection based countermeasures for invalid ciphertexts, and refreshing the secret key upon detection of an invalid ciphertext. This prevents further exposure of the secret key to the attacker and thus serves as an attractive option for protection against prior attacks. Thus, in this work, we present a critical analysis of the detection based countermeasure, and present the first side-channel based chosen-ciphertext attack that attempts to utilize only valid ciphertexts for key recovery, thereby defeating the detection based countermeasure. We propose novel attacks exploiting leakage from the ExpandAndSum and FindPeaks operations within the Reed-Muller decoder for full key recovery with 100% success rate. We show that our attacks are quite robust to noise in the side-channel measurements, and we also present novel extensions of our attack to the shuffling countermeasure on both the ExpandAndSum and FindPeaks operation, which renders the shuffling countermeasure ineffective. Our work therefore shows that low-cost detection based countermeasures can be rendered ineffective, and cannot offer standalone protection against CC-based side-channel attacks. Thus, our work encourages more study towards development of new low-cost countermeasures against CC-based side-channel attacks.",
        "authors": [
            "Thales Paiva",
            "Prasanna Ravi",
            "Dirmanto Jap",
            "Shivam Bhasin",
            "Sayan Das",
            "Anupam Chattopadhyay"
        ],
        "category": "Attacks and cryptanalysis",
        "lastmodified": "2024-11-06 06:15:15",
        "name": "2023/1626",
        "pdffile": "2023/1626.pdf",
        "pid": 1626,
        "title": "Et tu, Brute? SCA Assisted CCA using Valid Ciphertexts - A Case Study on HQC KEM",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "Despite decades of effort, a chasm exists between the theory and practice of device-level biometric authentication. Deployed authentication algorithms rely on data that overtly leaks private information about the biometric; thus systems rely on externalized security measures such as trusted execution environments. The authentication algorithms have no cryptographic guarantees.\r\n  \r\nThis is  frustrating given the research that has developed theoretical tools, known as fuzzy extractors, that enable secure, privacy-preserving biometric authentication with public enrollment data (Dodis et al., SIAM JoC 2008). Unfortunately, fuzzy extractor systems either:\r\n-Make strong independence assumptions, such as:\r\n-- Bits of biometrics are i.i.d. (or that all correlation is pairwise between features (Hine et al., TIFS 2023)), or\r\n-- For an error-correcting code, the nearest codeword and the coset of biometric readings are independent (Zhang, Cui, and Yu, ePrint 2021/1559).\r\n  These assumptions either have not been statistically checked or \r\n  statistical analysis indicates they are false.\r\n- Or use incorrect cryptographic analysis.  Simhadri et al. (ISC, 2019) assume the security of sample-then-lock (Canetti et al., Journal of Cryptology 2021) is captured by the average min-entropy of subsets.  Zhang et al. (ICPR, 2022) show an attack on this incorrect analysis. \r\n\r\nThis work introduces IrisLock, an iris key derivation system powered by technical advances in both\r\n1) feature extraction from the iris  and\r\n2) the fuzzy extractor used to secure authentication keys.  The fuzzy extractor builds on sample-then-lock (Canetti et al., Journal of Cryptology 2021). We correct a proof in Canetti et al. and show the minimum of min-entropy of subsets is the relevant security measure.  Our primary parameters are $42$ bits of security at $45\\%$ true accept rate (TAR).  Our quantitive level of security is as good as the above systems, Simhadri et al's incorrect analysis yields an estimate of $32$ bits, while Zhang et al.'s system on the face estimates $45$ bits (with the independence condition). One can easily incorporate a password, boosting security to $64$ bits.\r\n\r\nIrises used to evaluate TAR and security are class disjoint from those used for training and collecting statistics (the open dataset regime).\r\nThe only statistical assumption made is necessary: the accuracy of min-entropy estimation.",
        "authors": [
            "Sohaib Ahmad",
            "Sixia Chen",
            "Luke Demarest",
            "Benjamin Fuller",
            "Caleb Manicke",
            "Alexander Russell",
            "Amey Shukla"
        ],
        "category": "Applications",
        "lastmodified": "2024-11-06 01:01:57",
        "name": "2024/100",
        "pdffile": "2024/100.pdf",
        "pid": 100,
        "title": "IrisLock: Iris Biometric Key Derivation with 42 bits of security",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "The enormous potential of Attribute-Based Encryption (ABE) in the context of IoT has driven researchers to propose pairing-free ABE schemes that are suitable for resource-constrained devices. Unfortunately, many of these schemes turned out to be insecure. This fact seems to reinforce the point of view of some authors according to which instantiating an Identity-Based Encryption (IBE) in plain Decision Diffie-Hellman (DDH) groups is impossible. In this paper, we provide a generic AND gate access structured Ciphertext-Policy ABE (CP-ABE) scheme with secret access policy from Inner-Product Functional Encryption (IPFE). We also propose an instantiation of that generic CP-ABE scheme from the DDH assumption. From our generic CP-ABE scheme we derive an IBE scheme by introducing the concept of Clustered Identity-Based Encryption (CIBE). Our schemes show that it is indeed possible to construct practical and secure IBE and ABE schemes based on the classical DDH assumption.",
        "authors": [
            "Ahmad Khoureich Ka"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-05 17:25:27",
        "name": "2024/1779",
        "pdffile": "2024/1779.pdf",
        "pid": 1779,
        "title": "Ciphertext-Policy ABE from Inner-Product FE",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We propose a new trust metric for a network of public key certificates, e.g. as in PKI, which allows a user to buy insurance at a fair price on the possibility of failure of the certifications provided while transacting with an arbitrary party in the network.\r\nOur metric builds on a metric and model of insurance provided by Reiter and Stubblebine, while addressing various limitations and drawbacks of the latter. It conserves all the beneficial properties of the latter over other schemes, including protecting the user from unintentional or malicious dependencies in the network of certifications. Our metric is built on top of a simple\r\nand intuitive model of trust and risk based on ``utility sampling'', which maybe of interest for non-monetary applications as well.",
        "authors": [
            "Dakshi Agrawal",
            "Charanjit Jutla"
        ],
        "lastmodified": "2024-11-05 17:12:19",
        "name": "2007/178",
        "pdffile": "",
        "pid": 178,
        "psfile": "2007/178.ps",
        "title": "Utility Sampling for Trust Metrics in PKI",
        "withdrawn": 0,
        "year": 2007
    },
    {
        "abstract": "Non-interactive key exchange (NIKE) schemes like the Diffie-Hellman key exchange are a widespread building block in several cryptographic protocols. Since the Diffie-Hellman key exchange is not post-quantum secure, it is important to investigate post-quantum alternatives.\r\n\r\nWe analyze the security of the LWE-based NIKE by Ding et al. (ePrint 2012) and Peikert (PQCrypt 2014) in a multi-user setting where the same public key is used to generate shared keys with multiple other users. The Diffie-Hellman key exchange achieves this security notion. The mentioned LWE-based NIKE scheme comes with an inherent correctness error (Guo et al., PKC 2020), and this has significant implications for the multi-user security, necessitating a closer examination.\r\n\r\nSingle-user security generically implies multi-user security when all users generate their keys honestly for NIKE schemes with negligible correctness error. However, the LWE-based NIKE requires a super-polynomial modulus to achieve a negligible correctness error, which makes the scheme less efficient. We show that\r\n  - generically, single-user security does not imply multi-user security when the correctness error is non-negligible, but despite this\r\n  - the LWE-based NIKE with polynomial modulus is multi-user secure for honest users when the number of users is fixed in advance. This result takes advantage of the leakage-resilience properties of LWE.\r\n\r\nWe then turn to a stronger model of multi-user security that allows adversarially generated public keys. For this model, we consider a variant of the LWE-based NIKE where each public key is equipped with a NIZKPoK of the secret key. Adding NIZKPoKs is a standard technique for this stronger model and Hesse et al. (Crypto 2018) showed that this is sufficient to achieve security in the stronger multi-user security model for perfectly correct NIKEs (which the LWE-based NIKE is not). We show that\r\n  - for certain parameters that include all parameters with polynomial modulus, the LWE-based NIKE can be efficiently attacked with adversarially generated public keys, despite the use of NIZKPoKs, but\r\n  - for suitable parameters (that require a super-polynomial modulus), this security notion is achieved by the LWE-based NIKE with NIZKPoKs.\r\nThis stronger security notion has been previously achieved for LWE-based NIKE only in the QROM, while all our results are in the standard model.",
        "authors": [
            "Roman Langrehr"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-05 17:10:14",
        "name": "2023/1401",
        "pdffile": "2023/1401.pdf",
        "pid": 1401,
        "title": "On the Multi-User Security of LWE-based NIKE",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "Recently, Picnic3 has introduced several alternative LowMC instances, which prompts the cryptanalysis competition for LowMC. In this paper, we provide new solutions to the competition with full S-box layers under single-data complexity. First, we present a new guess-and-determine attack framework that achieves the best trade-off in complexity, while effectively enhancing two algorithms applicable to 2-round LowMC cryptanalysis. Next, we present a new meet-in-the-middle attack framework for 2-/3-round LowMC, which can gradually reduce the number of variables and narrow down the range of candidate keys in stages. As a result, our 3-stage MITM attacks have both lower time complexity and memory complexity than the best previous 2-round attacks proposed by Banik et al. at ASIACRYPT 2021, with memory reduced drastically by a factor of $ 2^{29.7} \\sim 2^{70.4} $.",
        "authors": [
            "Xingwei Ren",
            "Yongqiang Li",
            "Mingsheng Wang"
        ],
        "category": "Attacks and cryptanalysis",
        "lastmodified": "2024-11-05 14:22:10",
        "name": "2024/1304",
        "pdffile": "2024/1304.pdf",
        "pid": 1304,
        "title": "Improved Algebraic Attacks on Round-Reduced LowMC with Single-Data Complexity",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "In this paper we propose verifiable secret sharing (VSS) schemes\r\nsecure for any honest majority in the synchronous model, and that only use symmetric-key cryptographic tools, therefore having plausibly post-quantum security. Compared to the state-of-the-art scheme with these features (Atapoor et al., Asiacrypt `23), our main improvement lies on the complexity of the ``optimistic'' scenario where the dealer and all but a small number of receivers behave honestly in the sharing phase: in this case, the running time and download complexity (amount of information read) of each honest verifier is polylogarithmic and the total amount of broadcast information by the dealer is logarithmic; all these complexities were linear in the aforementioned work by Atapoor et al. At the same time, we preserve these complexities with respect to the previous work for the ``pessimistic'' case where the dealer or $O(n)$ receivers cheat actively.\r\nThe new VSS protocol is of interest in multiparty computations where each party runs one VSS as a dealer, such as distributed key generation protocols.\r\n\r\nOur main technical handle is a distributed zero-knowledge proof of low degreeness of a polynomial, in the model of Boneh et al. (Crypto `19) where the statement (in this case the evaluations of the witness polynomial) is distributed among several verifiers, each knowing one evaluation. Using folding techniques similar to FRI (Ben-Sasson et al., ICALP `18) we construct such a proof where each verifier receives polylogarithmic information and runs in polylogarithmic time.",
        "authors": [
            "Ignacio Cascudo",
            "Daniele Cozzo",
            "Emanuele Giunta"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-05 13:35:20",
        "name": "2024/838",
        "pdffile": "2024/838.pdf",
        "pid": 838,
        "title": "Verifiable Secret Sharing from Symmetric Key Cryptography with Improved Optimistic Complexity",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Public key cryptography can be based on integer factorization and\r\nthe discrete logarithm problem (DLP), applicable in multiplicative groups and\r\nelliptic curves. Regev\u2019s recent quantum algorithm was initially designed for the\r\nfactorization and was later extended to the DLP in the multiplicative group.\r\nIn this article, we further extend the algorithm to address the DLP for elliptic\r\ncurves. Notably, based on celebrated conjectures in Number Theory, Regev\u2019s\r\nalgorithm is asymptotically faster than Shor\u2019s algorithm for elliptic curves.\r\nOur analysis covers all cases where Regev\u2019s algorithm can be applied. We\r\nexamine the general framework of Regev\u2019s algorithm and offer a geometric\r\ndescription of its parameters. This preliminary analysis enables us to certify\r\nthe success of the algorithm on a particular instance before running it.\r\nIn the case of integer factorization, we demonstrate that there exists an in-\r\nfinite family of RSA moduli for which the algorithm always fails. On the other\r\nhand, when the parameters align with the Gaussian heuristics, we prove that\r\nRegev\u2019s algorithm succeeds. By noting that the algorithm naturally adapts\r\nto the multidimensional DLP, we proved that it succeeds for a certain range\r\nof parameters.",
        "authors": [
            "Razvan Barbulescu",
            "Mugurel Barcau",
            "Vicentiu Pasol"
        ],
        "category": "Attacks and cryptanalysis",
        "lastmodified": "2024-11-05 11:17:53",
        "name": "2024/1758",
        "pdffile": "2024/1758.pdf",
        "pid": 1758,
        "title": "A comprehensive analysis of Regev's quantum algorithm",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "This work introduces DEFIv2 - an efficient hash-and-sign digital signature scheme based on isotropic quadratic forms over a commutative ring of characteristic 0. The form is public, but the construction is a trapdoor that depends on the scheme's private key. For polynomial rings over integers and rings of integers of algebraic number fields, the cryptanalysis is reducible to solving a quadratic Diophantine equation over the ring or, equivalently, to solving a system of quadratic Diophantine equations over rational integers. It is still an open problem whether quantum computers will have any advantage in solving Diophantine problems.",
        "authors": [
            "Martin Feussner",
            "Igor Semaev"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-05 10:51:12",
        "name": "2024/679",
        "pdffile": "2024/679.pdf",
        "pid": 679,
        "title": "Isotropic Quadratic Forms, Diophantine equations and Digital Signatures, DEFIv2",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "This paper introduces a novel approach to enhancing cryp-\r\ntographic security. It proposes the use of one-time message sharing com-\r\nbined with Physically Unclonable Functions (PUF) to securely exchange\r\nkeys and generate an S-subbyte-box for encryption. This innovative tech-\r\nnique aims to elevate the security standards of cryptographic applica-\r\ntions.",
        "authors": [
            "Raja Adhithan Radhakrishnan"
        ],
        "lastmodified": "2024-11-05 10:37:29",
        "name": "2023/1752",
        "pdffile": "2023/1752.pdf",
        "pid": 1752,
        "title": "Secure Encryption and Key Exchange using Arbiter PUF",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "In an election where each voter may express $P$ preferences among $M$ possible choices, the Amun protocol allows to secure vote casting against over-the-shoulder adversaries, retaining privacy, fairness, end-to-end verifiability, and correctness.\r\n\r\nBefore the election, each voter receives a ballot containing valid and decoy tokens: only valid tokens contribute in the final tally, but they remain indistinguishable from the decoys.\r\nSince the voter is the only one who knows which tokens are valid (without being able to prove it to a coercer), over-the-shoulder attacks are thwarted.\r\n\r\nWe prove the security of the construction under the standard Decisional Diffie Hellman assumption in the random oracle model.",
        "authors": [
            "Riccardo Longo",
            "Chiara Spadafora"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-05 10:24:42",
        "name": "2021/851",
        "pdffile": "2021/851.pdf",
        "pid": 851,
        "title": "Amun: Securing E-Voting Against Over-the-Shoulder Coercion",
        "withdrawn": 0,
        "year": 2021
    },
    {
        "abstract": "This work resolves the open problem of whether verifiable delay functions (VDFs) can be constructed in the random oracle model.\r\nA VDF is a cryptographic primitive that requires a long time to compute (even with parallelization), but produces a unique output that is efficiently and publicly verifiable. \r\n\r\nWe prove that VDFs with \\emph{imperfect completeness} and \\emph{computational uniqueness} do not exist in the random oracle model. This also rules out black-box constructions of VDFs from other cryptographic primitives, such as one-way permutations and collision-resistant hash functions.\r\n\r\nPrior to our work, Mahmoody, Smith and Wu (ICALP 2020) prove that VDFs satisfying both \\emph{perfect completeness} and \\emph{perfect uniqueness} do not exist in the random oracle model; on the other hand, Ephraim, Freitag, Komargodski, and Pass (Eurocrypt 2020) construct VDFs with \\emph{perfect completeness} and \\emph{computational uniqueness} in the random oracle model assuming the hardness of repeated squaring. Our result is optimal -- we bridge the current gap between previously known impossibility results and existing constructions.",
        "authors": [
            "Ziyi Guan",
            "Artur Riazanov",
            "Weiqiang Yuan"
        ],
        "category": "Foundations",
        "lastmodified": "2024-11-05 09:59:41",
        "name": "2024/766",
        "pdffile": "2024/766.pdf",
        "pid": 766,
        "title": "Breaking Verifiable Delay Functions in the Random Oracle Model",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "In parallel with the standardization of lattice-based cryptosystems, the research community in Post-quantum Cryptography focused on non-lattice-based hard problems for constructing public-key cryptographic primitives. The Linear Code Equivalence (LCE) Problem has gained attention regarding its practical applications and cryptanalysis.\r\nRecent advancements, including the LESS signature scheme and its candidacy in the NIST standardization for additional signatures, supported LCE as a foundation for post-quantum cryptographic primitives. However, recent cryptanalytic results have revealed vulnerabilities in LCE-based constructions when multiple related public keys are available for one specific code rate. In this work, we generalize the proposed attacks to cover all code rates. We show that the complexity of recovering the private key from multiple public keys is significantly reduced for any code rate scenario. Thus, we advise against constructing specific cryptographic primitives using LCE.",
        "authors": [
            "Alessandro Budroni",
            "Andrea Natale"
        ],
        "category": "Attacks and cryptanalysis",
        "lastmodified": "2024-11-05 09:15:23",
        "name": "2024/1757",
        "pdffile": "2024/1757.pdf",
        "pid": 1757,
        "title": "On the Sample Complexity of Linear Code Equivalence for all Code Rates",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We present $\\textit{Rhombus}$, a new secure matrix-vector multiplication (MVM) protocol in the semi-honest two-party setting, which is able to be seamlessly integrated into existing privacy-preserving machine learning (PPML) frameworks and serve as the basis of secure computation in linear layers. \r\n$\\textit{Rhombus}$ adopts RLWE-based homomorphic encryption (HE) with coefficient encoding, which allows messages to be chosen from not only a field $\\mathbb{F}_p$ but also a ring $\\mathbb{Z}_{2^\\ell}$, where the latter supports faster computation in non-linear layers. To achieve better efficiency, we develop an input-output packing technique that reduces the communication cost incurred by HE with coefficient encoding by about $21\\times$, and propose a split-point picking technique that reduces the number of rotations to that sublinear in the matrix dimension. Compared to the recent protocol $\\textit{HELiKs}$ by Balla and Koushanfar (CCS'23), our implementation demonstrates that $\\textit{Rhombus}$ improves the whole performance of an MVM protocol by a factor of $7.4\\times \\sim 8\\times$, and improves the end-to-end performance of secure two-party inference of ResNet50 by a factor of $4.6\\times \\sim 18\\times$.",
        "authors": [
            "Jiaxing He",
            "Kang Yang",
            "Guofeng Tang",
            "Zhangjie Huang",
            "Li Lin",
            "Changzheng Wei",
            "Ying Yan",
            "Wei Wang"
        ],
        "category": "Applications",
        "lastmodified": "2024-11-05 07:37:38",
        "name": "2024/1611",
        "pdffile": "2024/1611.pdf",
        "pid": 1611,
        "title": "Rhombus: Fast Homomorphic Matrix-Vector Multiplication for Secure Two-Party Inference",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Searchable encryption is a cryptographic primitive that allows us to perform searches on encrypted data. Searchable encryption schemes require that ciphertexts do not leak information about keywords. However, most of the existing schemes do not achieve the security notion that trapdoors do not leak information. Shen et al. (TCC 2009) proposed a security notion called full security, which includes both ciphertext privacy and trapdoor privacy, but there are few fully secure constructions. Full security is defined for the secret key settings since it is known that public key schemes cannot achieve the trapdoor privacy in principle.\r\nIn this paper, we construct a query-bounded fully secure scheme from pseudorandom functions. In addition, we propose three types of efficient (unbounded) fully secure schemes. One of them is based on bilinear groups, and the others are besed on lattices. We then analyze the existing constructions. We then analyze the existing constructions. First, we simplify the Cheng et al. scheme (Information Sciences 2023) and prove its security. This scheme had not been proved to be secure. Second, we show that the Li-Boyen pairing-based scheme (IACR CiC 2024) does not achieve the trapdoor privacy, not as claimed.",
        "authors": [
            "Hirotomo Shinoki",
            "Hisayoshi Sato",
            "Masayuki Yoshino"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-05 06:50:43",
        "name": "2024/1632",
        "pdffile": "2024/1632.pdf",
        "pid": 1632,
        "title": "Fully Secure Searchable Encryption from PRFs, Pairings, and Lattices",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Quantum no-cloning theorem gives rise to the intriguing possibility of quantum copy protection where we encode a program or functionality in a quantum state such that a user in possession of k copies cannot create k+1 copies, for any k. Introduced by Aaronson (CCC'09) over a decade ago, copy protection has proven to be notoriously hard to achieve.  Previous work has been able to achieve copy-protection for various functionalities only in restricted models: (i) in the bounded collusion setting where k -> k+1 security is achieved for a-priori fixed collusion bound k (in the plain model with the same computational assumptions as ours, by Liu, Liu, Qian, Zhandry), or, (ii) only k -> 2k security is achieved (relative to a structured quantum oracle, by Aaronson).\r\n\r\nIn this work, we give the first unbounded collusion-resistant (i.e. multiple-copy secure) copy-protection schemes, answering the long-standing open question of constructing such schemes, raised by multiple previous works starting with Aaronson (CCC'09). \r\n\r\nMore specifically, we obtain the following results.\r\n- We construct (i) public-key encryption, (ii) public-key functional encryption, (iii) signature and (iv) pseudorandom function schemes whose keys are copy-protected against unbounded collusions in the plain model (i.e. without any idealized oracles), assuming (post-quantum) subexponentially secure iO and LWE. \r\n    \r\n- We show that any unlearnable functionality can be copy-protected against unbounded collusions, relative to a classical oracle. \r\n    \r\n- As a corollary of our results, we rule out the existence of hyperefficient quantum shadow tomography, \r\n* even given non-black-box access to the measurements, assuming subexponentially secure iO and LWE, or,\r\n * unconditionally relative to a quantumly accessible classical oracle, and hence answer an open question by Aaronson (STOC'18). \r\n\r\nWe obtain our results through a novel technique which uses identity-based encryption to construct multiple copy secure copy-protection schemes from 1-copy -> 2-copy secure schemes. We believe our technique is of independent interest.\r\n\r\nAlong the way, we also obtain the following results.\r\n- We define and prove the security of new collusion-resistant monogamy-of-entanglement games for coset states.\r\n - We construct a classical puncturable functional encryption scheme whose master secret key can be punctured at all functions f such that f(m_0) != f(m_1). This might also be of independent interest.",
        "authors": [
            "Alper \u00c7akan",
            "Vipul Goyal"
        ],
        "category": "Foundations",
        "lastmodified": "2024-11-04 21:12:27",
        "name": "2023/1841",
        "pdffile": "2023/1841.pdf",
        "pid": 1841,
        "title": "Unclonable Cryptography with Unbounded Collusions and Impossibility of Hyperefficient Shadow Tomography",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "Searchable Symmetric Encryption (SSE) has emerged as a promising tool for facilitating efficient query processing over encrypted data stored in un-trusted cloud servers. Several techniques have been adopted to enhance the efficiency and security of SSE schemes. The query processing costs, storage costs and communication costs of any SSE are directly related to the size of the encrypted index that is stored in the server. To our knowledge, there is no work directed towards minimizing the index size. In this paper we introduce a novel technique to directly reduce the index size of any SSE. Our proposed technique generically transforms any secure single keyword SSE into an equivalently functional and secure version with reduced storage requirements, resulting in faster search and reduced communication overhead. Our technique involves in arranging the set of document identifiers $\\mathsf{db}(w)$ related to a keyword $w$ in leaf nodes of a complete binary tree and eventually obtaining a succinct representation of the set $\\mathsf{db}(w)$. This small representation of $\\mathsf{db}(w)$ leads to smaller index sizes. We do an extensive theoretical analysis of our scheme and prove its correctness. In addition, our comprehensive experimental analysis validates the effectiveness of our scheme on real and simulated data and shows that it can be deployed in practical situations.",
        "authors": [
            "Debrup Chakraborty",
            "Avishek Majumder",
            "Subhabrata Samajder"
        ],
        "category": "Secret-key cryptography",
        "lastmodified": "2024-11-04 19:22:45",
        "name": "2024/1483",
        "pdffile": "2024/1483.pdf",
        "pid": 1483,
        "title": "Making Searchable Symmetric Encryption Schemes Smaller and Faster",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "The majority of fault-tolerant distributed algorithms are designed assuming a nominal corruption model, in which at most a fraction $f_n$ of parties can be corrupted by the adversary. However, due to the infamous Sybil attack, nominal models are not sufficient to express the trust assumptions in open (i.e., permissionless) settings. Instead, permissionless systems typically operate in a weighted model, where each participant is associated with a weight and the adversary can corrupt a set of parties holding at most a fraction $f_w$ of the total weight.\r\n\r\nIn this paper, we suggest a simple way to transform a large class of protocols designed for the nominal model into the weighted model. To this end, we formalize and solve three novel optimization problems, which we collectively call the weight reduction problems, that allow us to map large real weights into small integer weights while preserving the properties necessary for the correctness of the protocols. In all cases, we manage to keep the sum of the integer weights to be at most linear in the number of parties, resulting in extremely efficient protocols for the weighted model. Moreover, we demonstrate that, on weight distributions that emerge in practice, the sum of the integer weights tends to be far from the theoretical worst case and, sometimes, even smaller than the number of participants.\r\n\r\nWhile, for some protocols, our transformation requires an arbitrarily small reduction in resilience (i.e., $f_w = f_n - \\epsilon$), surprisingly, for many important problems, we manage to obtain weighted solutions with the same resilience ($f_w = f_n$) as nominal ones. Notable examples include erasure-coded distributed storage and broadcast protocols, verifiable secret sharing, and asynchronous consensus. Although there are ad-hoc weighted solutions to some of these problems, the protocols yielded by our transformations enjoy all the benefits of nominal solutions, including simplicity, efficiency, and a wider range of possible cryptographic assumptions.",
        "authors": [
            "Andrei Tonkikh",
            "Luciano Freitas"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-04 16:18:53",
        "name": "2023/1164",
        "pdffile": "2023/1164.pdf",
        "pid": 1164,
        "title": "Swiper: a new paradigm for efficient weighted distributed protocols",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "Bitcoin enables decentralized, pseudonymous transactions, but balancing privacy with accountability remains a challenge. This paper introduces a novel dual accountability mechanism that enforces both sender and recipient compliance in Bitcoin transactions. Senders are restricted to spending Unspent Transaction Outputs (UTXOs) that meet specific criteria, while recipients must satisfy legal and ethical requirements before receiving funds. We enhance stealth addresses by integrating compliance attributes, preserving privacy while ensuring policy adherence. Our solution introduces a new cryptographic primitive, Identity-Based Matchmaking Signatures (IB-MSS), which supports streamlined auditing. Our approach is fully compatible with existing Bitcoin infrastructure and does not require changes to the core protocol, preserving both privacy and decentralization while enabling transaction auditing and compliance.",
        "authors": [
            "Alberto Maria Mongardini",
            "Daniele Friolo",
            "Giuseppe Ateniese"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-04 12:53:33",
        "name": "2024/1789",
        "pdffile": "2024/1789.pdf",
        "pid": 1789,
        "title": "Stealth and Beyond: Attribute-Driven Accountability in Bitcoin Transactions",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "In this work, we construct a second price (Vickrey) auction protocol (SPA), which does not require any auctioneers and ensures total privacy in the presence of rational parties participating in auction. In particular, the confidentiality of the highest bid and the identity of the second highest bidder are protected. We model the bidders participating in the second price auction as rational, computationally bounded and privacy-sensitive parties. These are self-interested agents who care about winning the auction more than learning about the private bids of other parties. A rational party does not deviate from the protocol arbitrarily but does so only for its own individual `advantage' -- without any consideration for others. Such an advantage is modeled using suitable utility functions. \r\n\r\nWe show that for rational and computationally bounded parties participating in our second-price auctions protocol, there exists a privacy-preserving dominant strategy equilibrium in which every party prefers to follow the protocol rather than to deviate. \r\n\r\nOur protocol is implemented using open-source cryptographic constructs. Running our SPA protocol on commodity hardware with $15$ bidders,  with bids of length $10$ bits,  completes in $1.26$sec and has total communication of $0.77$MB whereas, under similar conditions, Atlas (semi-honest) protocol takes $40\\%$ more time ($2.11$ sec) and $87\\%$ more communication ($6.09$MB).",
        "authors": [
            "Chaya Ganesh",
            "Shreyas Gupta",
            "Bhavana Kanukurthi",
            "Girisha Shankar"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-04 10:41:37",
        "name": "2024/1011",
        "pdffile": "2024/1011.pdf",
        "pid": 1011,
        "title": "Secure Vickrey Auctions with Rational Parties",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "In this paper, we investigate whether the privacy mechanism of periodically changing the pseudorandom identities of Bluetooth Low Energy (BLE) beacons is sufficient to ensure privacy.\r\n\r\nWe consider a new natural privacy notion for BLE broadcasting beacons which we call ``Timed-sequence- indistinguishability'' of beacons. This new privacy definition is stronger than the well-known indistinguishability, since it considers not just the advertisements' content, but also the advertisements' broadcasting times which are observable in the physical world. \r\n\r\nWe then prove that beacons with periodically changing pseudorandom identities do not achieve timed-sequence- indistinguishability. We do this by presenting a novel privacy attack against BLE beacons, which we call the ``Timer Manipulation Attack.'' This new time-based privacy attack can be executed by merely inserting or reinserting the beacon's battery at the adversary's chosen time. We performed this attack against an actually deployed beacon.\r\n\r\nTo mitigate the ``Timer Manipulation Attack'' and other attacks associated with periodic signaling, we propose a new countermeasure involving quasi-periodic randomized scheduling of identity changes. We prove that our countermeasure ensures timed-sequence indistinguishability for beacons, thereby enhancing the beacon's privacy. Additionally, we show how to integrate this countermeasure in the attacked system while essentially preserving its feasibility and utility, which is crucial for practical industrial adoption.",
        "authors": [
            "Liron David",
            "Avinatan Hassidim",
            "Yossi Matias",
            "Moti Yung"
        ],
        "category": "Attacks and cryptanalysis",
        "lastmodified": "2024-11-04 07:44:15",
        "name": "2024/1782",
        "pdffile": "2024/1782.pdf",
        "pid": 1782,
        "title": "Is Periodic Pseudo-randomization Sufficient for Beacon Privacy?",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "A spectre is haunting consensus protocols\u2014the spectre of adversary majority. The literature is inconclusive, with possibilities and impossibilities running abound. Dolev and Strong in 1983 showed an early possibility for up to 99% adversaries. Yet, we have known impossibility results for adversaries above 1/2 in synchrony, and above 1/3 in partial synchrony. What gives? It is high time that we pinpoint the culprit of this confusion: the critical role of the modeling details of clients. Are the clients sleepy or always-on? Are they silent or communicating? Can validators be sleepy too? We systematize models for consensus across four dimensions (sleepy/always-on clients, silent/communicating clients, sleepy/always-on validators, and synchrony/partial-synchrony), some of which are new, and tightly characterize the achievable safety and liveness resiliences with matching possibilities and impossibilities for each of the sixteen models. To this end, we unify folklore and earlier results, and fill gaps left in the literature with new protocols and impossibility theorems.",
        "authors": [
            "Srivatsan Sridhar",
            "Ertem Nusret Tas",
            "Joachim Neu",
            "Dionysis Zindros",
            "David Tse"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-03 21:22:17",
        "name": "2024/1799",
        "pdffile": "2024/1799.pdf",
        "pid": 1799,
        "title": "Consensus Under Adversary Majority Done Right",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "The meteoric rise in power and popularity of machine learning models dependent on valuable training data has reignited a basic tension between the power of running a program locally and the risk of exposing details of that program to the user. At the same time, fundamental properties of quantum states offer new solutions to data and program security that can require strikingly few quantum resources to exploit, and offer advantages outside of mere computational run time. In this work, we demonstrate such a solution with quantum one-time tokens.\r\n\r\nA quantum one-time token is a quantum state that permits a certain program to be evaluated exactly once. One-time security guarantees, roughly, that the token cannot be used to evaluate the program more than once. We propose a scheme for building quantum one-time tokens for any randomized classical program, which include generative AI models. We prove that the scheme satisfies an interesting definition of one-time security as long as outputs of the classical algorithm have high enough min-entropy, in a black box model.\r\n\r\nImportantly, the classical program being protected does not need to be implemented coherently on a quantum computer. In fact, the size and complexity of the quantum one-time token is independent of the program being protected, and additional quantum resources serve only to increase the security of the protocol. Due to this flexibility in adjusting the security, we believe that our proposal is parsimonious enough to serve as a promising candidate for a near-term useful demonstration of quantum computing in either the NISQ or early fault tolerant regime.",
        "authors": [
            "Sam Gunn",
            "Ramis Movassagh"
        ],
        "category": "Foundations",
        "lastmodified": "2024-11-03 18:24:08",
        "name": "2024/1798",
        "pdffile": "2024/1798.pdf",
        "pid": 1798,
        "title": "Quantum One-Time Protection of any Randomized Algorithm",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "\\textit{Federated Learning} (FL) is a distributed machine learning paradigm that allows multiple clients to train models collaboratively without sharing local data. Numerous works have explored security and privacy protection in FL, as well as its integration with blockchain technology. However, existing FL works still face critical issues.  \\romannumeral1) It is difficult to achieving \\textit{poisoning robustness} and \\textit{data privacy} while ensuring high \\textit{model accuracy}. Malicious clients can launch \\textit{poisoning attacks} that degrade the global model. Besides, aggregators can infer private data from the gradients, causing \\textit{privacy leakages}. Existing privacy-preserving poisoning defense FL solutions suffer from decreased model accuracy and high computational overhead. \\romannumeral2) Blockchain-assisted FL records iterative gradient updates on-chain to prevent model tampering, yet existing schemes are not compatible with practical blockchains and incur high costs for maintaining the gradients on-chain. Besides, incentives are overlooked, where unfair reward distribution hinders the sustainable development of the FL community. In this work, we propose FLock, a robust and privacy-preserving FL scheme based on practical blockchain state channels. First, we propose a lightweight secure \\textit{Multi-party Computation} (MPC)-friendly robust aggregation method through quantization, median, and Hamming distance, which could resist poisoning attacks against up to $<50\\%$ malicious clients. Besides, we propose communication-efficient Shamir's secret sharing-based MPC protocols to protect data privacy with high model accuracy. Second, we utilize blockchain off-chain state channels to achieve immutable model records and incentive distribution. FLock achieves cost-effective compatibility with practical cryptocurrency platforms, e.g. Ethereum, along with fair incentives, by merging the secure aggregation into a multi-party state channel. In addition, a pipelined \\textit{Byzantine Fault-Tolerant} (BFT) consensus is integrated where each aggregator can reconstruct the final aggregated results. Lastly, we implement FLock and the evaluation results demonstrate that FLock enhances robustness and privacy, while maintaining efficiency and high model accuracy. Even with 25 aggregators and 100 clients, FLock can complete one secure aggregation for ResNet in $2$ minutes over a WAN. FLock successfully implements secure aggregation with such a large number of aggregators, thereby enhancing the fault tolerance of the aggregation.",
        "authors": [
            "Ruonan Chen",
            "Ye Dong",
            "Yizhong Liu",
            "Tingyu Fan",
            "Dawei Li",
            "Zhenyu Guan",
            "Jianwei Liu",
            "Jianying Zhou"
        ],
        "category": "Applications",
        "lastmodified": "2024-11-03 16:32:03",
        "name": "2024/1797",
        "pdffile": "2024/1797.pdf",
        "pid": 1797,
        "title": "FLock: Robust and Privacy-Preserving Federated Learning based on Practical Blockchain State Channels",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "The Supersingular Isogeny Diffie-Hellman (SIDH) scheme is a public key cryptosystem that was submitted to the National Institute of Standards and Technology's competition for the standardization of post-quantum cryptography protocols. The private key in SIDH consists of an isogeny whose degree is a prime power. In July 2022, Castryck and Decru discovered an attack that completely breaks the scheme by recovering Bob's secret key, using isogenies between higher dimensional abelian varieties to interpolate and reconstruct the isogenies comprising the SIDH private key. The original attack applies in theory to any prime power degree, but the implementation accompanying the original attack required one of the SIDH keys involved in a key exchange to have degree equal to a power of $2$. An implementation of the power of $3$ case was published subsequently by Decru and Kunzweiler. However, despite the passage of several years, nobody has published any implementations for prime powers other than $2$ or $3$, and for good reason --- the necessary higher dimensional isogeny computations rapidly become more complicated as the base prime increases. In this paper, we provide for the first time a fully general isogeny interpolation implementation that works for any choice of base prime, and provide timing benchmarks for various combinations of SIDH base prime pairs. We remark that the technique of isogeny interpolation now has constructive applications as well as destructive applications, and that our methods may open the door to increased flexibility in constructing isogeny-based digital signatures and cryptosystems.",
        "authors": [
            "David Jao",
            "Jeanne Laflamme"
        ],
        "category": "Implementation",
        "lastmodified": "2024-11-03 13:50:22",
        "name": "2024/1796",
        "pdffile": "2024/1796.pdf",
        "pid": 1796,
        "title": "Isogeny interpolation and the computation of isogenies from higher dimensional representations",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "For a finite field $\\mathbb{F}$ of size $n$, the (patched) inverse permutation $\\operatorname{INV}: \\mathbb{F} \\to \\mathbb{F}$  computes the inverse of $x$ over $\\mathbb{F}$ when $x\\neq 0$ and outputs $0$ when $x=0$, and the $\\operatorname{ARK}_K$ (for AddRoundKey) permutation adds a fixed constant $K$ to its input, i.e.,\r\n$$\\operatorname{INV}(x) = x^{n-2} \\hspace{.1in} \\mbox{and} \\hspace{.1in} \\operatorname{ARK}_K(x) = x + K \\;.$$\r\nWe study the process of alternately applying the $\\operatorname{INV}$ permutation followed by a random linear permutation $\\operatorname{ARK}_K$, which is a random walk over the alternating (or symmetric) group that we call the inverse walk.\r\n\r\nWe show both lower and upper bounds on the number of rounds it takes for this process to approximate a random permutation over $\\mathbb{F}$. We show that $r$ rounds of the inverse walk over the field of size $n$ with $$r = \\Theta\\left(n\\log^2 n + n\\log n\\log \\frac{1}{\\epsilon}\\right)$$ rounds generates a permutation that is $\\epsilon$-close (in variation distance) to a uniformly random even permutation (i.e. a permutation from the alternating group $A_{n}$). This is tight, up to logarithmic factors.\r\n\r\nOur result answers an open question from the work of Liu, Pelecanos, Tessaro and Vaikuntanathan (CRYPTO 2023) by providing a missing piece in their proof of $t$-wise independence of (a variant of) AES. It also constitutes a significant improvement on a result of Carlitz (Proc. American Mathematical Society, 1953) who showed a reachability result: namely, that every even permutation can be generated eventually by composing $\\operatorname{INV}$ and $\\operatorname{ARK}$. We show a tight convergence result, namely a tight quantitative bound on the number of rounds to reach a random (even) permutation.",
        "authors": [
            "Tianren Liu",
            "Angelos Pelecanos",
            "Stefano Tessaro",
            "Vinod Vaikuntanathan"
        ],
        "category": "Secret-key cryptography",
        "lastmodified": "2024-11-03 04:00:03",
        "name": "2024/1795",
        "pdffile": "2024/1795.pdf",
        "pid": 1795,
        "title": "How Fast Does the Inverse Walk Approximate a Random Permutation?",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Modern blockchain-based consensus protocols \r\naim for efficiency (i.e., low communication and round complexity) while maintaining security against adaptive adversaries.\r\nThese goals are usually achieved using a public randomness beacon to select roles for each participant.  \r\nWe examine to what extent this randomness is necessary.\r\nSpecifically, we provide tight bounds on the amount of entropy a Byzantine Agreement protocol must consume from a beacon in order to enjoy efficiency and adaptive security.\r\nWe first establish that no consensus protocol can simultaneously be efficient, be adaptively secure, and use $O(\\log n)$ bits of beacon entropy. We then show this bound is tight and, in fact, a trilemma by presenting three consensus protocols that achieve any two of these three properties.",
        "authors": [
            "Joseph Bonneau",
            "Benedikt B\u00fcnz",
            "Miranda Christ",
            "Yuval Efron"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-02 18:00:29",
        "name": "2024/1794",
        "pdffile": "2024/1794.pdf",
        "pid": 1794,
        "title": "How Much Public Randomness Do Modern Consensus Protocols Need?",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We suggest two families of multivariate public keys defined over arbitrary finite commutative ring \\(K\\) with unity. The first one has quadratic multivariate public rule, this family is an obfuscation of previously defined cryptosystem defined in terms of well known algebraic graphs \\(D(n, K)\\) with the partition sets isomorphic to \\(K^n\\). Another family of cryptosystems uses the combination of Eulerian transformation of \\(K[x_1, x_2, \\ldots, x_n]\\) sending each variable \\(x_i\\) to a monomial term with the quadratic encryption map of the first cryptosystem. The resulting map has unbounded degree and the density \\(O(n^4)\\) like the cubic multivariate map. The space of plaintexts of the second cryptosystem is the variety \\((K^*)^n\\) and the space of ciphertexts is the affine space \\(K^n\\).",
        "authors": [
            "Vasyl Ustimenko",
            "Tymoteusz Chojecki",
            "Aneta Wr\u00f3blewska"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-02 17:37:10",
        "name": "2024/1793",
        "pdffile": "2024/1793.pdf",
        "pid": 1793,
        "title": "On the Jordan-Gauss graphs and new multivariate  public keys",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "In this note we review the technique proposed at ToSC 2018 by Sadeghi et al. for attacks built upon several related-tweakey impossible differential trails. We show that the initial encryption queries are improper and lead the authors to misevaluate a filtering value in the key recovery phase. We identified 4 other papers (from Eurocrypt, DCC, and 2 from ToSC) that follow on the results of Sadeghi et al., and in three of them the flawed technique was reused.\r\n\r\nWe thus present a careful analysis of these types of attacks and give generic complexity formulas similar to the ones proposed by Boura et al. at Asiacrypt 2014. \r\nWe apply these to the aforementioned papers and provide patched versions of their attacks. The main consequence is an increase in the memory complexity. We show that in many cases (a notable exception being quantum impossible differentials) it is possible to recover the numeric time estimates of the flawed analysis, and in all cases we were able to build a correct attack reaching the same number of rounds.",
        "authors": [
            "Xavier Bonnetain",
            "Virginie Lallemand"
        ],
        "category": "Attacks and cryptanalysis",
        "lastmodified": "2024-11-02 17:09:47",
        "name": "2024/563",
        "pdffile": "2024/563.pdf",
        "pid": 563,
        "title": "A Note on Related-Tweakey Impossible Differential Attacks",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We explore the use of microbenchmarks, small assembly code snippets, to detect microarchitectural side-channel leakage in CPU implementations. Specifically, we investigate the effectiveness of microbenchmarks in diagnosing the predisposition to side-channel leaks in two commonly used RISC-V cores: Picorv32 and Ibex. We propose a new framework that involves diagnosing side-channel leaks, identifying leakage points, and constructing leakage profiles to understand the underlying causes. We apply our framework to several realistic case studies that test our framework for explaining side-channel leaks and showcase the subtle interaction of data via order-reducing leaks.",
        "authors": [
            "Ischa Stork",
            "Vipul Arora",
            "\u0141ukasz Chmielewski",
            "Ileana Buhan"
        ],
        "category": "Implementation",
        "lastmodified": "2024-11-02 17:00:55",
        "name": "2024/1792",
        "pdffile": "2024/1792.pdf",
        "pid": 1792,
        "title": "Towards Explainable Side-Channel Leakage: Unveiling the Secrets of Microarchitecture",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Discrete Gaussian sampling on lattices is a fundamental problem in lattice-based cryptography. In this paper, we revisit the Markov chain Monte Carlo (MCMC)-based Metropolis-Hastings-Klein (MHK) algorithm proposed by Wang and Ling\r\nand study its complexity under the Geometric Series Assuption (GSA) when the given basis is BKZ-reduced. We give experimental evidence that the GSA is accurate in this context, and we give a very simple approximate formula for the complexity of the sampler that is accurate over a large range of parameters and easily computable. We apply our results to the dual attack on LWE of and significantly improve the complexity estimates of the attack. Finally, we provide some results of independent interest on the Gaussian mass of a random $q$-ary lattices.",
        "authors": [
            "Amaury Pouly",
            "Yixin Shen"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-02 10:41:17",
        "name": "2024/1791",
        "pdffile": "2024/1791.pdf",
        "pid": 1791,
        "title": "Discrete gaussian sampling for BKZ-reduced basis",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "In 2023, Koshelev proposed an efficient method for subgroup membership testing on a list of non-pairing-friendly curves via the Tate pairing. In fact, this method can also be applied to certain pairing-friendly curves, such as the BLS and BW13 families, at a cost of two small Tate pairings. In this paper, we revisit Koshelev's method to enhance its efficiency for these curve families. First, we present explicit formulas for computing the two small Tate pairings. Compared to the original formulas, the new versions offer shorter Miller iterations and reduced storage requirements. Second, we provide a high-speed software implementation on a 64-bit processor. Our results demonstrate that the new method is up to $62.0\\%$ and $22.4\\%$ faster   than the state-of-the-art on the BW13-310 and BLS24-315 curves, respectively, while being $14.1\\%$ slower on BLS12-381. When precomputation is utilized, our method achieves speed improvements of up to $34.8\\%$, $110.6\\%$, and $63.9\\%$ on the BLS12-381, BW13-310, and BLS24-315 curves, respectively.",
        "authors": [
            "Yu Dai",
            "Debiao He",
            "Dmitrii Koshelev",
            "Cong Peng",
            "Zhijian Yang"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-02 09:47:12",
        "name": "2024/1790",
        "pdffile": "2024/1790.pdf",
        "pid": 1790,
        "title": "Revisiting subgroup membership testing on pairing-friendly curves via the Tate pairing",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Homomorphic encryption can address key privacy challenges in cloud-based outsourcing by enabling potentially untrusted servers to perform meaningful computation directly on encrypted data. While most homomorphic encryption schemes offer addition and multiplication over ciphertexts natively, any non-linear functions must be implemented as costly polynomial approximations due to this restricted computational model. Nevertheless, the CGGI cryptosystem is capable of performing arbitrary univariate functions over ciphertexts in the form of lookup tables through the use of programmable bootstrapping. While promising, this procedure can quickly become costly when high degrees of precision are required. To address this challenge, we propose Ripple: a framework that introduces different approximation methodologies based on discrete wavelet transforms (DWT) to decrease the number of entries in homomorphic lookup tables while maintaining high accuracy. Our empirical evaluations demonstrate significant error reduction compared to plain quantization methods across multiple non-linear functions. Notably, Ripple improves runtime performance for several realistic benchmarks, such as logistic regression and cross-correlation, among others.",
        "authors": [
            "Charles Gouert",
            "Mehmet Ugurbil",
            "Dimitris Mouris",
            "Miguel de Vega",
            "Nektarios Georgios Tsoutsos"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-01 17:30:14",
        "name": "2024/866",
        "pdffile": "2024/866.pdf",
        "pid": 866,
        "title": "Ripple: Accelerating Programmable Bootstraps for FHE with Wavelet Approximations",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We show that there exists a unitary quantum oracle relative to which quantum commitments exist but no (efficiently verifiable) one-way state generators exist. Both have been widely considered candidates for replacing one-way functions as the minimal assumption for cryptography\u2014the weakest cryptographic assumption implied by all of computational cryptography. Recent work has shown that commitments can be constructed from one-way state generators, but the other direction has remained open. Our results rule out any black-box construction, and thus settle this crucial open problem, suggesting that quantum commitments (as well as its equivalency class of EFI pairs, quantum oblivious transfer, and secure quantum multiparty computation) appear to be strictly weakest among all known cryptographic primitives.",
        "authors": [
            "John Bostanci",
            "Boyang Chen",
            "Barak Nehoran"
        ],
        "category": "Foundations",
        "lastmodified": "2024-11-01 16:32:51",
        "name": "2024/1568",
        "pdffile": "2024/1568.pdf",
        "pid": 1568,
        "title": "Oracle Separation Between Quantum Commitments and Quantum One-wayness",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We present a succinct polynomial commitment scheme for multilinears over tiny binary fields, including that with just two elements. To achieve this, we develop two main ideas. Our first adapts Zeilberger, Chen and Fisch's BaseFold ('23) PCS to the binary setting; it uses FRI (ICALP '18)'s lesser-known binary variant, and reveals a new connection between that work and Lin, Chung and Han (FOCS '14)'s additive NTT. We moreover present a novel large-field-to-small-field compiler for polynomial commitment schemes. Using a technique we call \"ring-switching\", our compiler generically bootstraps any multilinear PCS over a large, power-of-two degree extension field into a further PCS over that field's ground field. The resulting small-field PCS lacks embedding overhead, in that its commitment cost is identical to that of the large-field scheme on each input size (measured in bits). We attain concretely small proofs for enormous binary multilinears, shrinking the proofs of Diamond and Posen ('23) by an order of magnitude.",
        "authors": [
            "Benjamin E. Diamond",
            "Jim Posen"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-01 15:47:07",
        "name": "2024/504",
        "pdffile": "2024/504.pdf",
        "pid": 504,
        "title": "Polylogarithmic Proofs for Multilinears over Binary Towers",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Lattices lead to  promising practical post-quantum digital signatures, combining asymptotic efficiency with strong theoretical security guarantees. However, tuning their parameters into practical instantiations is a delicate task. On the one hand, NIST round 2 candidates based on Lyubashevsky's design (such as Dilithium and qTesla) allow several tradeoffs between security and efficiency, but at the expense of a large bandwidth consumption. On the other hand, the hash-and-sign falcon signature is much more compact and is still very efficient, but it allows only two security levels, with large compactness and security gaps between them.\r\n\r\nWe introduce a new family of signature schemes based on the Falcon design, which relies on module lattices. Our concrete instantiation enjoys the compactness and efficiency of Falcon, and allows an intermediate security level. It leads to the most compact lattice-based signature achieving a quantum security above 128 bits.",
        "authors": [
            "Chitchanok Chuengsatiansup",
            "Thomas Prest",
            "Damien Stehl\u00e9",
            "Alexandre Wallet",
            "Keita Xagawa"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-01 15:11:57",
        "name": "2019/1456",
        "pdffile": "2019/1456.pdf",
        "pid": 1456,
        "title": "ModFalcon: compact signatures based on module NTRU lattices",
        "withdrawn": 0,
        "year": 2019
    },
    {
        "abstract": "In contemporary times, there are many situations where users need to verify that their information is correctly retained by servers. At the same time, servers need to maintain transparency logs. Many algorithms have been designed to address this problem. For example, Certificate Transparency (CT) helps track certificates issued by Certificate Authorities (CAs), while CONIKS aims to provide key transparency for end users. However, these algorithms often suffer from either high append time or imbalanced inclusion-proof cost and consistency-proof cost. To find an optimal solution, we constructed two different but similar authenticated data structures tailored to two different lookup protocols. We propose ATS (Advanced Transparency System), which uses only linear storage cost to reduce append time and balances the time costs for both servers and users. When addressing the value-lookup problem, this system allows servers to append user information in constant time and enables radical-level inclusion proof and consistency proof. For the key transparency problem, the system requires logarithmic time complexity for the append operation and offers acceptable inclusion proof and consistency proof.",
        "authors": [
            "Yuxuan Sun",
            "Yuncong Hu",
            "Yu Yu"
        ],
        "category": "Applications",
        "lastmodified": "2024-11-01 14:29:53",
        "name": "2024/1788",
        "pdffile": "2024/1788.pdf",
        "pid": 1788,
        "title": "Advanced Transparency System",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Private Set Intersection (PSI) allows two mutually untrusted parties to compute the intersection of their private sets without revealing additional information. In general, PSI operates in a static setting, where the computation is performed only once on the input sets of both parties. Badrinarayanan et al. (\\textit{PoPETs} 2022) initiated the study of Updatable PSI (UPSI), which extends this capability to dynamically updating sets, enabling both parties to securely compute the intersection as their sets are modified while incurring significantly less overhead than re-executing a conventional PSI. However, existing UPSI protocols either do not support arbitrary deletion of elements or incur high computational and communication overhead. In this work, we combine asymmetric PSI with Private Set Union (PSU) to present a novel UPSI protocol. Our UPSI protocol supports arbitrary additions and deletions of elements, offering a flexible approach to update sets. Furthermore, our protocol enjoys extremely low communication overhead, scaling linearly with the size of the update set while remaining independent of the total set size. We implement our protocol and compare it against state-of-the-art conventional PSI and UPSI protocols. Experimental results demonstrate that our UPSI protocol incurs $587\\sim 755 \\times$ less communication overhead than the recently proposed UPSI protocol (\\textit{AsiaCrypt} 2024) that supports arbitrary additions and deletions. Moreover, our UPSI protocol also has a significant advantage in running time, achieving an improvement of two to three orders of magnitude, especially in low-bandwidth environments due to the exceptionally low communication overhead. Specifically, with an input size of $2^{22}$ and the size of the addition/deletion set being $2^{8}$, the existing UPSI protocol requires approximately $1650.45$, $1789.5$, and $3458.1$ seconds at bandwidths of $200$ Mbps, $50$ Mbps, and $5$ Mbps, respectively, whereas our UPSI protocol only requires around $3.16$, $3.35$, and $5.65$ seconds under the same conditions. Our open-source implementation is available at: \\href{https://github.com/ShallMate/upsi}{https://github.com/ShallMate/upsi}.",
        "authors": [
            "Guowei Ling",
            "Peng Tang",
            "Weidong Qiu"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-01 14:28:53",
        "name": "2024/1712",
        "pdffile": "2024/1712.pdf",
        "pid": 1712,
        "title": "Low-Communication Updatable PSI from Asymmetric PSI and PSU",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Boolean functions play an important role in designing and analyzing many cryptographic systems, such as block ciphers, stream ciphers, and hash functions, due to their unique cryptographic properties such as nonlinearity, correlation immunity, and algebraic properties. The secure evaluation of Boolean functions or Secure Boolean Evaluation (SBE) is an important area of research. SBE allows parties to jointly compute Boolean functions without exposing their private inputs. SBE finds applications in privacy-preserving protocols and secure multi-party computations. In this manuscript, we present an efficient and generic two-party protocol\r\n(namely $\\textsf{BooleanEval}$) for the secure evaluation of Boolean functions by utilizing a 1-out-of-2 Oblivious Transfer (OT) as a building block. $\\textsf{BooleanEval}$ only employs XOR operations as the core computational step, thus making it lightweight and fast. Unlike other lightweight state-of-the-art designs of SBE, $\\textsf{BooleanEval}$ avoids the use of additional cryptographic primitives, such as hash functions and commitment schemes to reduce the computational overhead.",
        "authors": [
            "Sushmita Sarkar",
            "Vikas Srivastava",
            "Tapaswini Mohanty",
            "Nibedita Kundu",
            "Sumit Kumar Debnath"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-01 14:02:24",
        "name": "2024/1787",
        "pdffile": "2024/1787.pdf",
        "pid": 1787,
        "title": "An Efficient and Secure Boolean Function Evaluation Protocol",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "A Timed Commitment (TC) with time parameter $t$ is hiding for time at most $t$, that is, commitments can be force-opened by any third party within time $t$. In addition to various cryptographic assumptions, the security of all known TC schemes relies on the sequentiality assumption of repeated squarings in hidden-order groups. The repeated squaring assumption is therefore  a security bottleneck. \r\n\r\nIn this work, we give a black-box construction of TCs from any time-lock puzzle (TLP) by additionally relying on one-way permutations and collision-resistant hashing.\r\n\r\nCurrently, TLPs are known from (a) the specific repeated squaring assumption, (b) the general (necessary) assumption on the existence of worst-case non-parallelizing languages and indistinguishability obfuscation, and (c) any iteratively sequential function and the hardness of the circular small-secret LWE problem. The latter admits a plausibly post-quantum secure instantiation. \r\n\r\nHence, thanks to the generality of our transform, we get i) the first TC whose timed security is based on the the existence of non-parallelizing languages and ii) the first TC that is plausibly post-quantum secure.\r\n\r\nWe first define quasi publicly-verifiable TLPs (QPV-TLPs) and construct them from any standard TLP in a black-box manner without relying on any additional assumptions. Then, we devise a black-box commit-and-prove system to transform any QPV-TLPs into a TC.",
        "authors": [
            "Hamza Abusalah",
            "Gennaro Avitabile"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-01 13:07:56",
        "name": "2024/1786",
        "pdffile": "2024/1786.pdf",
        "pid": 1786,
        "title": "Black-Box Timed Commitments from Time-Lock Puzzles",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Aaronson, Atia, and Susskind established that efficiently mapping between quantum states $\\ket{\\psi}$ and $\\ket{\\phi}$ is computationally equivalent to distinguishing their superpositions $\\frac{1}{\\sqrt{2}}(|\\psi\\rangle + |\\phi\\rangle)$ and $\\frac{1}{\\sqrt{2}}(|\\psi\\rangle - |\\phi\\rangle)$. We generalize this insight into a broader duality principle in quantum computation, wherein manipulating quantum states in one basis is equivalent to extracting their value in a complementary basis. In its most general form, this duality principle states that for a given group, the ability to implement a unitary representation of the group is computationally equivalent to the ability to perform a Fourier subspace extraction from the invariant subspaces corresponding to its irreducible representations.\r\n\r\nBuilding on our duality principle, we present the following applications:\r\n\r\n* Quantum money, which captures quantum states that are verifiable but unclonable, and its stronger variant, quantum lightning, have long resisted constructions based on concrete cryptographic assumptions. While (public-key) quantum money has been constructed from indistinguishability obfuscation (iO)\u2014an assumption widely considered too strong\u2014quantum lightning has not been constructed from any such assumptions, with previous attempts based on assumptions that were later broken. We present the first construction of quantum lightning with a rigorous security proof, grounded in a plausible and well-founded cryptographic assumption. We extend Zhandry's construction from Abelian group actions to non-Abelian group actions, and eliminate Zhandry's reliance on a black-box model for justifying security. Instead, we prove a direct reduction to a computational assumption\u2014the pre-action security of cryptographic group actions. We show how these group actions can be realized with various instantiations, including with the group actions of the symmetric group implicit in the McEliece cryptosystem.\r\n\r\n* We provide an alternative quantum money and lightning construction from one-way homomorphisms, showing that security holds under specific conditions on the homomorphism. Notably, our scheme exhibits the remarkable property that four distinct security notions\u2014quantum lightning security, security against both worst-case cloning and average-case cloning, and security against preparing a specific canonical state\u2014are all equivalent.\r\n\r\n* Quantum fire captures the notion of a samplable distribution on quantum states that are efficiently clonable, but not efficiently telegraphable, meaning they cannot be efficiently encoded as classical information. These states can be spread like fire, provided they are kept alive quantumly and do not decohere.\r\nThe only previously known construction relied on a unitary quantum oracle, whereas we present the first candidate construction of quantum fire in the plain model.",
        "authors": [
            "John Bostanci",
            "Barak Nehoran",
            "Mark Zhandry"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-01 12:59:52",
        "name": "2024/1785",
        "pdffile": "2024/1785.pdf",
        "pid": 1785,
        "title": "A General Quantum Duality for Representations of Groups with Applications to Quantum Money, Lightning, and Fire",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "This article aims to speed up (the precomputation stage of) multi-scalar multiplication (MSM) on ordinary elliptic curves of $j$-invariant $0$ with respect to specific ''independent'' (a.k.a. ''basis'') points. For this purpose, so-called Mordell--Weil lattices (up to rank $8$) with large kissing numbers (up to $240$) are employed. In a nutshell, the new approach consists in obtaining more efficiently a considerable number (up to $240$) of certain elementary linear combinations of the ``independent'' points. By scaling the point (re)generation process, it is thus possible to get a significant performance gain. As usual, the resulting curve points can be then regularly used in the main stage of an MSM algorithm to avoid repeating computations. Seemingly, this is the first usage of lattices with large kissing numbers in cryptography, while such lattices have already found numerous applications in other mathematical domains. Without exaggeration, the article results can strongly affect performance of today's real-world elliptic curve cryptography, since MSM is a widespread primitive (often the unique bottleneck) in modern protocols. Moreover, the new (re)generation technique is prone to further improvements by considering Mordell--Weil lattices with even greater kissing numbers.",
        "authors": [
            "Dmitrii Koshelev"
        ],
        "category": "Implementation",
        "lastmodified": "2024-11-01 12:12:35",
        "name": "2023/1384",
        "pdffile": "2023/1384.pdf",
        "pid": 1384,
        "title": "Application of Mordell-Weil lattices with large kissing numbers to acceleration of multi-scalar multiplication on elliptic curves",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "In this paper, we study multi-party non-interactive key exchange (NIKE) in the fine-grained setting. More precisely, we propose three multi-party NIKE schemes in three computation models, namely, the bounded parallel-time, bounded time, and bounded storage models. Their security is based on a very mild assumption (e.g., NC1 \u228a \u2295L/poly) or even without any complexity assumption. This improves the recent work of Afshar, Couteau, Mahmoody, and Sadeghi (EUROCRYPT 2023) that requires idealized assumptions, such as random oracles or generic groups.\r\nAdditionally, we show that all our constructions satisfy a natural desirable property that we refer to as extendability, and we give generic transformations from extendable multi-party NIKE to multi-party identity-based NIKEs in the fine-grained settings.",
        "authors": [
            "Yuyu Wang",
            "Chuanjie Su",
            "Jiaxin Pan"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-01 11:41:45",
        "name": "2024/1784",
        "pdffile": "2024/1784.pdf",
        "pid": 1784,
        "title": "Fine-Grained Non-Interactive Key-Exchange without Idealized Assumptions",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We present a key-policy attribute-based encryption (ABE) scheme for circuits based on the Learning With Errors (LWE) assumption whose key size is independent of the circuit depth. Our result constitutes the first improvement for ABE for circuits from LWE in almost a decade, given by Gorbunov, Vaikuntanathan, and Wee (STOC 2013) and Boneh, et al. (EUROCRYPT 2014) -- we reduce the key size in the latter from\r\n$\\mathsf{poly}(\\mbox{depth},\\lambda)$ to $\\mathsf{poly}(\\lambda)$. The starting point of our construction is a recent ABE scheme of Li, Lin, and Luo (TCC 2022), which achieves $\\mathsf{poly}(\\lambda)$ key size but requires pairings and generic bilinear groups in addition to LWE; we introduce new lattice techniques to eliminate the additional requirements.",
        "authors": [
            "Valerio Cini",
            "Hoeteck Wee"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-01 10:44:31",
        "name": "2024/1780",
        "pdffile": "2024/1780.pdf",
        "pid": 1780,
        "title": "ABE for Circuits with $\\mathsf{poly}(\\lambda)$-sized Keys from LWE",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We present the formal verification of Apple\u2019s iMessage PQ3, a highly performant, device-to-device messaging protocol offering strong security guarantees even against an adversary with quantum computing capabilities. PQ3 leverages Apple\u2019s identity services together with a custom, post-quantum secure initialization phase and afterwards it employs a double ratchet construction in the style of Signal, extended to provide post-quantum, post-compromise security.\r\n\r\nWe present a detailed formal model of PQ3, a precise specification of its fine-grained security properties, and machine-checked security proofs using the TAMARIN prover. Particularly novel is the integration of post-quantum secure key encapsulation into the relevant protocol phases and the detailed security claims along with their complete formal analysis. Our analysis covers both key ratchets, including unbounded loops, which was believed by some to be out of scope of symbolic provers like TAMARIN (it is not!).",
        "authors": [
            "Felix Linker",
            "Ralf Sasse",
            "David Basin"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-01 10:33:22",
        "name": "2024/1395",
        "pdffile": "2024/1395.pdf",
        "pid": 1395,
        "title": "A Formal Analysis of Apple\u2019s iMessage PQ3 Protocol",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Service discovery is essential in wireless communications. However, existing service discovery protocols provide no or very limited privacy protection for service providers and clients, and they often leak sensitive information (e.g., service type, client\u2019s identity and mobility pattern), which leads to various network-based attacks (e.g., spoofing, man-in-the-middle, identification and tracking). In this paper, we propose a private service discovery protocol, called PriSrv, which allows a service provider and a client to respectively specify a fine-grained authentication policy that the other party must satisfy before a connection is established. PriSrv consists of a private service broadcast phase and an anonymous mutual authentication phase with bilateral control, where the private information of both parties is hidden beyond the fact that a mutual match to the respective authentication policy occurred. As a core component of PriSrv, we introduce the notion of anonymous credential-based matchmaking encryption (ACME), which exerts dual-layer matching in one step to simultaneously achieve bilateral  flexible policy control, selective attribute disclosure and multi-show unlinkability. As a building block of ACME, we design a fast anonymous credential (FAC) scheme to provide constant size credentials and efficient show/verification mechanisms, which is suitable for privacy-enhanced and highly usable service discovery in wireless networks. We present a concrete PriSrv protocol that is interoperable with popular wireless communication protocols, such as Wi-Fi Extensible Authentication Protocol (EAP), mDNS, BLE and Airdrop, to offer privacy-enhanced protection. We present formal security proof of our protocol and evaluate its performance on multiple hardware platforms: desktop, laptop, mobile phone and Raspberry Pi. PriSrv accomplishes private discovery and secure connection in less than 0.973 s on the first three platforms, and in less than 2.712 s on Raspberry Pi 4B. We also implement PriSrv into IEEE 802.1X in the real network to demonstrate its practicality.",
        "authors": [
            "Yang Yang",
            "Robert H. Deng",
            "Guomin Yang",
            "Yingjiu Li",
            "HweeHwa Pang",
            "Minming Huang",
            "Rui Shi",
            "Jian Weng"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-01 10:02:29",
        "name": "2024/1783",
        "pdffile": "2024/1783.pdf",
        "pid": 1783,
        "title": "PriSrv: Privacy-Enhanced and Highly Usable Service Discovery in Wireless Communications",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Quantum computational advantage refers to an existence of computational tasks that are easy for quantum computing but hard for classical one. Unconditionally showing quantum advantage is beyond our current understanding of complexity theory, and therefore some computational assumptions are needed. Which complexity assumption is necessary and sufficient for quantum advantage? In this paper, we show that inefficient-verifier proofs of quantumness (IV-PoQ) exist if and only if classically-secure one-way puzzles (OWPuzzs) exist. As far as we know, this is the first time that a complete cryptographic characterization of quantum advantage is obtained. IV-PoQ capture various types of quantum advantage previously studied, such as sampling-based quantum advantage and searching-based one. Previous work showed that IV-PoQ can be constructed from OWFs, but a construction of IV-PoQ from weaker assumptions was left open. Our result solves the open problem. OWPuzzs are one of the most fundamental quantum cryptographic primitives implied by many quantum cryptographic primitives weaker than one-way functions (OWFs). The equivalence between IV-PoQ and classically-secure OWPuzzs therefore highlights that if there is no quantum advantage, then these fundamental primitives do not exist. The equivalence also means that quantum advantage is an example of the applications of OWPuzzs. Except for commitments, no application of OWPuzzs was known before. Our result shows that quantum advantage is another application of OWPuzzs, which solves the open question of. Moreover, it is the first quantum-computation-classical-communication (QCCC) application of OWPuzzs.",
        "authors": [
            "Tomoyuki Morimae",
            "Yuki Shirakawa",
            "Takashi Yamakawa"
        ],
        "category": "Foundations",
        "lastmodified": "2024-11-01 08:57:59",
        "name": "2024/1536",
        "pdffile": "2024/1536.pdf",
        "pid": 1536,
        "title": "Cryptographic Characterization of Quantum Advantage",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "The succinct non-interactive argument of knowledge (SNARK) technique has been extensively utilized in blockchain systems to replace the costly on-chain computation with the verification of a succinct proof. However, most existing applications verify each proof independently, resulting in a heavy load on nodes and high transaction fees for users. Currently, the mainstream proof aggregation schemes are based on a generalized inner product argument, which has a logarithmic proof size and verification cost. To improve the efficiency of verifying multiple proofs, we introduce SnarkFold, a novel SNARK-proof aggregation scheme with constant verification time and proof size. SnarkFold is derived from incrementally verifiable computation (IVC) and is optimized further through the folding scheme. By folding multiple instance-proof pairs, SnarkFold defers the expensive SNARK verification (e.g., elliptic curve pairing) to the final step. Additionally, we propose a generic technique to enhance the verifier's efficiency by delegating instance aggregation tasks to the prover. The verifier only needs a simple preprocessing to check the validity of the delegation. We further introduce folding schemes for Groth16 and Plonk proofs. Experimental results demonstrate that SnarkFold offers significant advantages, with an aggregated Plonk proof size of just $0.5$ KB and the verification time of only $4.5$ ms for aggregating 4096 Plonk proofs.",
        "authors": [
            "Xun Liu",
            "Shang Gao",
            "Tianyu Zheng",
            "Yu Guo",
            "Bin Xiao"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-01 05:56:27",
        "name": "2023/1946",
        "pdffile": "2023/1946.pdf",
        "pid": 1946,
        "title": "SnarkFold: Efficient Proof Aggregation from Incrementally Verifiable Computation and Applications",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "Most existing MPC protocols consider the homogeneous setting, where all the MPC players are assumed to have identical communication and computation resources. In practice, the player with the least resources often becomes the bottleneck of the entire MPC protocol execution. In this work, we initiate the study of so-called \\emph{load-balanced MPC} in heterogeneous computing. A load-balanced MPC protocol can adjust the workload of each player accordingly to maximize the overall resource utilization. In particular, we propose new notions called composite circuit and composite garbling scheme, and construct two efficient server-aided protocols with malicious security and semi-honest security, respectively. Our maliciously secure protocol is over 400$\\times$ faster than the authenticated garbling protocol (CCS '17) and up to 4.3$\\times$ faster than the state-of-the-art server-aided MPC protocol of Lu  et al. (TDSC '23); our semi-honest protocol is up to 173$\\times$ faster than the optimized BMR protocol (CCS '16) and is up to 3.8$\\times$ faster than the protocol of Lu et al.",
        "authors": [
            "Yibiao Lu",
            "Bingsheng Zhang",
            "Kui Ren"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-11-01 04:35:01",
        "name": "2023/1826",
        "pdffile": "2023/1826.pdf",
        "pid": 1826,
        "title": "Load-Balanced Server-Aided MPC in Heterogeneous Computing",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "MPC-in-the-Head (MPCitH) has recently gained traction as a foundation for post-quantum signature schemes, offering robust security without trapdoors. Despite its strong security profile, MPCitH-based schemes suffer from high computational overhead and large signature sizes, limiting their practical application. \r\n\r\nThis work addresses these inefficiencies by relaxing vector commitments within MPCitH-based schemes. We introduce the concept of vector semi-commitment, which relaxes the binding property of traditional vector commitment. Vector semi-commitment schemes may allow an adversary to find more than one preimage of a commitment. We instantiate vector semi-commitment schemes in both the random oracle model and the ideal cipher model, leveraging recent optimizations on GGM tree such as correlated GGM tree. \r\n\r\nWe apply the ideal-cipher-based vector semi-commitment scheme to the BN++ signature scheme and prove it fully secure in the ideal cipher model. Implementing these improvements in the $\\mathsf{AIMer}$ v2.0 signature scheme, we achieve up to 18% shorter signatures and up to 112% faster signing and verification speeds, setting new benchmarks for MPCitH-based schemes.",
        "authors": [
            "Seongkwang Kim",
            "Byeonghak Lee",
            "Mincheol Son"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-11-01 02:08:36",
        "name": "2024/1004",
        "pdffile": "2024/1004.pdf",
        "pid": 1004,
        "title": "Relaxed Vector Commitment for Shorter Signatures",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Bitcoin, while being the most prominent blockchain with the largest market capitalization, suffers from scalability and throughput limitations that impede the development of ecosystem projects like Bitcoin Decentralized Finance (BTCFi). Recent advancements in BitVM propose a promising Layer 2 (L2) solution to enhance Bitcoin's scalability by enabling complex computations off-chain with on-chain verification. However, Bitcoin's constrained programming environment\u2014characterized by its non-Turing-complete Script language lacking loops and recursion, and strict block size limits\u2014makes developing complex applications labor-intensive, error-prone, and necessitates manual partitioning of scripts. Under this complex programming model, subtle mistakes could lead to irreversible damage in a trustless environment like Bitcoin. Ensuring the correctness and security of such programs becomes paramount.\r\n\r\nTo address these challenges, we introduce the first formal verification tool for BitVM implementations. Our approach involves designing a register-based, higher-level domain-specific language (DSL) that abstracts away complex stack operations, allowing developers to reason about program correctness more effectively while preserving the semantics of the original Bitcoin Script. We present a formal computational model capturing the semantics of BitVM execution and Bitcoin Script, providing a foundation for rigorous verification. To efficiently handle large programs and complex constraints arising from unrolled computations that simulate loops, we summarize repetitive \"loop-style\" computations using loop invariant predicates in our DSL. We leverage a counterexample-guided inductive synthesis (CEGIS) procedure to lift low-level Bitcoin Script into our DSL, facilitating efficient verification without sacrificing accuracy. Evaluated on 98 benchmarks from BitVM's SNARK verifier, our tool successfully verifies 94% of cases within seconds, demonstrating its effectiveness in enhancing the security and reliability of BitVM.",
        "authors": [
            "Hanzhi Liu",
            "Jingyu Ke",
            "Hongbo Wen",
            "Robin Linus",
            "Lukas George",
            "Manish Bista",
            "Hakan Karaku\u015f",
            "Domo",
            "Junrui Liu",
            "Yanju Chen",
            "Yu Feng"
        ],
        "category": "Implementation",
        "lastmodified": "2024-10-31 23:57:08",
        "name": "2024/1768",
        "pdffile": "2024/1768.pdf",
        "pid": 1768,
        "title": "Push-Button Verification for BitVM Implementations",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We say there is a share conversion from a secret sharing scheme $\\Pi$ to another scheme $\\Pi'$ implementing the same access structure if each party can locally apply a deterministic function to their share to transform any valid secret sharing under $\\Pi$ to a valid (but not necessarily random) secret sharing under $\\Pi'$ of the same secret. If such a conversion exists, we say that $\\Pi\\ge\\Pi'$. This notion was introduced by Cramer et al. (TCC'05),  where they particularly proved that for any access structure (AS), any linear secret sharing scheme over a given field $\\mathbb{F}$, has a conversion from a CNF scheme, and is convertible to a DNF scheme.\r\n      In this work, we initiate a systematic study of convertability between secret sharing schemes, and present a number of results with implications to the understanding of the convertibility landscape.\r\n        -  In the context of linear schemes, we present two key theorems  providing necessary conditions for convertibility, proved using linear-algebraic tools. It has several implications, such as the fact that Shamir secret sharing scheme can be neither maximal or minimal. Another implication of it is that for a broad class of access structures, a linear scheme where some party has sufficiently small  share complexity, may not be minimal.\r\n       -  Our second key result is a necessary condition for convertibility to CNF from a broad class of (not necessarily linear) schemes. This result is proved via information-theoretic techniques and implies non-maximality for schemes with share complexity smaller than that of CNF.\r\n      We also provide a condition which is both necessary and sufficient for the existence of a share conversion to some linear scheme. The condition is stated as a system of linear equations, such that a conversion exists iff. a solution to the linear system exists. We note that the impossibility results for linear schemes may be viewed as identifying a subset of contradicting equations in the system.\r\n      Another contribution of our paper, is in defining and studying share conversion for evolving secret sharing schemes. In such a schemes, recently introduced by Komargodski et al. (IEEE ToIT'18), the number of parties is not bounded apriori, and every party receives a share as it arrives, which never changes in the sequel. Our impossibility results have implications to the evolving setting as well. Interestingly, that unlike the standard setting, there is no maximum or minimum in a broad class of evolving schemes, even without any restriction on the share size.\r\n      Finally, we show that, generally, there is no conversion between additive schemes over different fields, however by degrading to statistical security, it may be possible to create convertible schemes.",
        "authors": [
            "Tamar Ben David",
            "Varun Narayanan",
            "Olga Nissenbaum",
            "Anat Paskin-Cherniavsky"
        ],
        "category": "Foundations",
        "lastmodified": "2024-10-31 17:11:09",
        "name": "2024/1781",
        "pdffile": "2024/1781.pdf",
        "pid": 1781,
        "title": "New results in Share Conversion, with applications to evolving access structures",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Numerous applications in homomorphic encryption require an operation that moves the slots of a ciphertext to the coefficients of a different ciphertext. For the BGV and BFV schemes, the only efficient algorithms to implement this slot-to-coefficient transformation were proposed in the setting of non-power-of-two cyclotomic rings. In this paper, we devise an FFT-like method to decompose the slot-to-coefficient transformation (and its inverse) for power-of-two cyclotomic rings. The proposed method can handle both fully and sparsely packed slots. Our algorithm brings down the computational complexity of the slot-to-coefficient transformation from a linear to a logarithmic number of FHE operations, which is shown via a detailed complexity analysis.\r\n\r\nThe new procedures are implemented in Microsoft SEAL for BFV. The experiments report a speedup of up to $44\\times$ when packing $2^{12}$ elements from $\\operatorname{GF}(8191^8)$. We also study a fully packed bootstrapping operation that refreshes $2^{15}$ elements from $\\operatorname{GF}(65537)$ and obtain an amortized speedup of $12\\times$.",
        "authors": [
            "Robin Geelen"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-10-31 16:18:44",
        "name": "2024/153",
        "pdffile": "2024/153.pdf",
        "pid": 153,
        "title": "Revisiting the Slot-to-Coefficient Transformation for BGV and BFV",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "LLL-style lattice reduction algorithms iteratively employ size reduction and reordering on ordered basis vectors to find progressively shorter, more orthogonal vectors. DeepLLL reorders the basis through deep insertions, yielding much shorter vectors than LLL. DeepLLL was introduced alongside BKZ, however, the latter has received greater attention and has emerged as the state-of-the-art. We first show that LLL-style algorithms work with a designated measure of basis quality and iteratively improves it; specifically, DeepLLL improves a sublattice measure based on the generalised Lov\u00e1sz condition. We then introduce a new generic framework X-GG for lattice reduction algorithms that work with a measure X of basis quality. X-GG globally searches for deep insertions that minimise X in each iteration. We instantiate the framework with two quality measures \u2014 basis potential (Pot) and squared sum (SS) \u2014 both of which have corresponding DeepLLL algorithms. We prove polynomial runtimes for our X-GG algorithms and also prove their output to be X-DeepLLL reduced. Our experiments on non-preprocessed bases show that X-GG produces better quality outputs whilst being much faster than the corresponding DeepLLL algorithms. We also compare SS-GG and the FPLLL implementation of BKZ with LLL-preprocessed bases. In small dimensions (40 to 210), SS-GG is significantly faster than BKZ with block sizes 8 to 12, while simultaneously also providing better output quality in most cases. In higher dimensions (250 and beyond), by varying the threshold $\\delta$ for deep insertion, SS-GG offers new trade-offs between the output quality and runtime. On the one hand, it provides significantly better runtime than BKZ-5 with worse output quality; on the other hand, it is significantly faster than BKZ-21 while providing increasingly better output quality after around dimension 350.",
        "authors": [
            "Sanjay Bhattacherjee",
            "Julio Hernandez-Castro",
            "Jack Moyler"
        ],
        "category": "Foundations",
        "lastmodified": "2024-10-31 15:36:16",
        "name": "2023/261",
        "pdffile": "2023/261.pdf",
        "pid": 261,
        "title": "A Greedy Global Framework for Lattice Reduction Using Deep Insertions",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "HAWK is a lattice-based signature scheme candidate to the fourth call of the NIST's Post-Quantum standardization campaign. Considered as a cousin of Falcon (one of the future NIST post-quantum standards) one can wonder whether HAWK shares the same drawbacks as Falcon in terms of side-channel attacks. Indeed, Falcon signature algorithm and particularly its Gaussian sampler, has shown to be highly vulnerable to power-analysis attacks. Besides, efficiently protecting Falcon's signature algorithm against these attacks seems a very challenging task.\r\n\r\nThis work presents the first power analysis leakage review on HAWK signature scheme: it extensively assesses the vulnerabilities of a central and sensitive brick of the scheme, the discrete Gaussian sampler. Knowing the output x of the sampler for a given signature leads to linear information about the private key of the scheme.\r\n\r\nThis paper includes several demonstrations of simple power analysis attacks targeting this sample x with various attacker strengths, all of them performed on the reference implementation on a ChipWhisperer Lite with STM32F3 target (ARM Cortex M4). We report being able to perform key recoveries with very low (to no) offline resources. As this reference implementation of HAWK is not claimed to be protected against side-channel attacks, the existence of such attacks is not surprising, but they still concretely warn about the use of this unprotected signature on physical devices.\r\n\r\nTo go further, our study proposes a generic way of assessing the performance of a side-channel attack on x even when less information is recovered, in a setting where some protections are implemented or when the attacker has less measurement possibilities. While it is easy to see that x is a sensitive value, quantifying the residual complexity of the key recovery with some knowledge about x (like the parity or the sign of some coefficients) is not straightforward as the underlying hardness assumption is the newly introduced Module-LIP problem. We propose to adapt the existing methodology of leaky LWE estimation tools (Dachman-Soled et al. at Crypto 2020) to exploit the retrieved information and lower down the residual key recovery complexity.\r\n\r\nTo finish, we propose an ad-hoc technique to lower down the leakage on the identified vulnerability points. These modifications prevent our attacks on our platform and come with essentially no cost in terms of performance. It could be seen as a temporary solution and encourages more analysis on proven side-channel protection of HAWK like masking.",
        "authors": [
            "Morgane Guerreau",
            "M\u00e9lissa Rossi"
        ],
        "category": "Attacks and cryptanalysis",
        "lastmodified": "2024-10-31 14:47:52",
        "name": "2024/1248",
        "pdffile": "2024/1248.pdf",
        "pid": 1248,
        "title": "A Not So Discrete Sampler: Power Analysis Attacks on HAWK signature scheme",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Yu et al. described an algorithm for conducting computational searches for quadratic APN functions over the finite field $\\mathbb{F}_{2^n}$, and used this algorithm to give a classification of all quadratic APN functions with coefficients in $\\mathbb{F}_{2}$  for dimensions $n$ up to 9. In this paper, we speed up the running time of that algorithm by a factor of approximately $\\frac{n \\times 2^n}{n^3}$. Based on this result, we give a complete classification of all quadratic APN functions over $\\mathbb{F}_{2^{10}}$ with coefficients in $\\mathbb{F}_{2}$. We also perform some partial computations for quadratic APN functions over $\\mathbb{F}_{2^{11}}$ with coefficients in $\\mathbb{F}_{2}$ , and conjecture that they form 6 CCZ-inequivalent classes which also correspond to known APN functions.",
        "authors": [
            "Yuyin Yu",
            "Jingchen Li",
            "Nadiia Ichanska",
            "Nikolay Kaleyski"
        ],
        "category": "Foundations",
        "lastmodified": "2024-10-31 13:43:11",
        "name": "2024/1778",
        "pdffile": "2024/1778.pdf",
        "pid": 1778,
        "title": "Construction of quadratic APN functions with coefficients in $\\mathbb{F}_2$ in dimensions $10$ and $11$",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Digital signature schemes based on multivariate- and code-based hard problems are promising alternatives for lattice-based signature schemes, due to their smaller signature size. Hence, several candidates in the ongoing additional standardization for quantum secure digital signature (DS) schemes by the National Institute of Standards and Technology (NIST) rely on such alternate hard problems. Gaussian Elimination (GE) is a critical component in the signing procedure of these schemes. In this paper, we provide a masking scheme for GE with back substitution to defend against first- and higher-order attacks. To the best of our knowledge, this work is the first to analyze and propose masking techniques for multivariate- or code-based DS algorithms.\r\nWe propose a masked algorithm for transforming a system of linear equations into row-echelon form. This is realized by introducing techniques for efficiently making leading (pivot) elements one while avoiding costly conversions between Boolean and multiplicative masking at all orders. We also propose a technique for efficient masked back substitution, which eventually enables a secure unmasking of the public output. We evaluate the overhead of our countermeasure for several post-quantum candidates and their different security levels at first-, second-, and third-order, including UOV, MAYO, SNOVA, QR-UOV, and MQ-Sign. Notably, the operational cost of first-, second-, and third-order masked GE is 2.3$\\times$ higher, and the randomness cost is 1.2$\\times$ higher in MAYO compared to UOV for security levels III and V. In contrast, these costs are similar in UOV and MAYO for one version of level I. We also show detailed performance results for masked GE implementations for all three security versions of UOV on the Arm Cortex-M4 and compare them with unmasked results. Our first-order implementations targeting UOV parameters have overheads of factor 6.5$\\times$, 5.9$\\times$, and 5.7$\\times$ compared to the unprotected implementation for NIST security level I, III, and V.",
        "authors": [
            "Quinten Norga",
            "Suparna Kundu",
            "Uttam Kumar Ojha",
            "Anindya Ganguly",
            "Angshuman Karmakar",
            "Ingrid Verbauwhede"
        ],
        "category": "Implementation",
        "lastmodified": "2024-10-31 12:56:18",
        "name": "2024/1777",
        "pdffile": "2024/1777.pdf",
        "pid": 1777,
        "title": "Masking Gaussian Elimination at Arbitrary Order, with Application to Multivariate- and Code-Based PQC",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "A major challenge of any asynchronous MPC protocol is the need to reach an agreement on the set of private inputs to be used as input for the MPC functionality. Ben-Or, Canetti and Goldreich call this problem Agreement on a Core Set (ACS) and solve it by running $n$ parallel instances of asynchronous binary Byzantine agreements. To the best of our knowledge, all results in the perfect and statistical security setting used this same paradigm for solving ACS. Using all known asynchronous binary Byzantine agreement protocols, this type of ACS has $\\Omega(\\log n)$ expected round complexity, which results in such a bound on the round complexity of asynchronous MPC protocols as well (even for constant depth circuits).\r\n\r\nWe provide a new solution for Agreement on a Core Set that runs in expected $O(1)$ rounds. Our perfectly secure variant is optimally resilient ($t<n/4$) and requires just $O(n^4\\log n)$ expected communication complexity. We show a similar result with statistical security for $t<n/3$. Our ACS is based on a new notion of Asynchronously Validated Asynchronous Byzantine Agreement (AVABA) and new information-theoretic analogs to techniques used in the authenticated model. Along the way, we also construct a new perfectly secure packed asynchronous verifiable secret sharing (AVSS) protocol with just $O(n^3\\log n)$ communication complexity, improving the state of the art by a factor of $O(n)$. This leads to a more efficient asynchronous MPC that matches the state-of-the-art synchronous MPC.",
        "authors": [
            "Ittai Abraham",
            "Gilad Asharov",
            "Arpita Patra",
            "Gilad Stern"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-10-31 12:27:56",
        "name": "2023/1130",
        "pdffile": "2023/1130.pdf",
        "pid": 1130,
        "title": "Asynchronous Agreement on a Core Set in Constant Expected Time and More Efficient Asynchronous VSS and MPC",
        "withdrawn": 0,
        "year": 2023
    },
    {
        "abstract": "Censorship circumvention tools enable clients to access endpoints in a network despite the presence of a censor. Censors use a variety of techniques to identify content they wish to block, including filtering traffic patterns that are characteristic of proxy or circumvention protocols and actively probing potential proxy servers. Circumvention practitioners have developed fully encrypted protocols (FEPs), intended to have traffic that appears indistinguishable from random. A FEP is typically composed of a key exchange protocol to establish shared secret keys, and then a secure channel protocol to encrypt application data; both must avoid revealing to observers that an obfuscated protocol is in use.\r\n\r\nWe formalize the notion of obfuscated key exchange, capturing the requirement that a key exchange protocol's traffic \"looks random\" and that it resists active probing attacks, in addition to ensuring secure session keys and authentication. We show that the Tor network's obfs4 protocol satisfies this definition. We then show how to extend the obfs4 design to defend against stronger censorship attacks and present a quantum-safe obfuscated key exchange protocol. To instantiate our quantum-safe protocol using the ML-KEM (Kyber) standard, we present Kemeleon, a new mapping between ML-KEM public keys/ciphertexts and uniform byte strings.",
        "authors": [
            "Felix G\u00fcnther",
            "Douglas Stebila",
            "Shannon Veitch"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-10-31 10:18:38",
        "name": "2024/1086",
        "pdffile": "2024/1086.pdf",
        "pid": 1086,
        "title": "Obfuscated Key Exchange",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "In 2020, Castryck-Decru-Smith constructed a hash function, using the (2,2)-isogeny graph of superspecial principally polarized abelian surfaces. In their construction, the initial surface was chosen from vertices very \"close\" to the square of a supersingular elliptic curve with a known endomorphism ring.\r\nIn this paper, we introduce an algorithm for detecting a collision on their hash function. Under some heuristic assumptions, the time complexity and space complexity of our algorithm are estimated to be $\\widetilde{O}(p^{3/10})$ which are smaller than the complexity $\\widetilde{O}(p^{3/2})$ the authors claimed to be necessary to detect a collision, where $p$ is the characteristic of the base field. In particular case where $p$ has a special form, then both the time and space complexities of our algorithm are polynomial in $\\log{p}$. We implemented our algorithm in Magma, and succeeded in detecting a collision in 17 hours (using 64 parallel computations) under a parameter setting which the authors had claimed to be 384-bit secure.",
        "authors": [
            "Ryo Ohashi",
            "Hiroshi Onuki"
        ],
        "category": "Attacks and cryptanalysis",
        "lastmodified": "2024-10-31 06:51:51",
        "name": "2024/1776",
        "pdffile": "2024/1776.pdf",
        "pid": 1776,
        "title": "An efficient collision attack on Castryck-Decru-Smith\u2019s hash function",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "In this paper, we introduce zkMarket, a privacy-preserving fair trade system on the blockchain. zkMarket addresses the challenges of transaction privacy and computational efficiency. To ensure transaction privacy, zkMarket is built upon an anonymous transfer protocol. By combining encryption with zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARK), both the seller and the buyer are enabled to trade fairly. Furthermore, by encrypting the decryption key, we make the data registration process more concise and improve the seller's proving time by leveraging commit-and-prove SNARK (CP-SNARK) and our novel pseudorandom generator, the matrix-formed PRG (MatPRG).\r\n\r\nOur evaluation demonstrates that zkMarket significantly reduces the computational overhead associated with traditional blockchain solutions while maintaining robust security and privacy. The seller can register 1MB of data in 3.2 seconds, while the buyer can generate the trade transaction in 0.2 seconds, and the seller can finalize the trade in 0.4 seconds.",
        "authors": [
            "Seungwoo Kim",
            "Semin Han",
            "Seongho Park",
            "Kyeongtae Lee",
            "Jihye Kim",
            "Hyunok Oh"
        ],
        "category": "Applications",
        "lastmodified": "2024-10-31 04:47:17",
        "name": "2024/1775",
        "pdffile": "2024/1775.pdf",
        "pid": 1775,
        "title": "zkMarket : Privacy-preserving Digital Data Trade System via Blockchain",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Approximate nearest neighbor search (ANNS), also known as\r\nvector search, is an important building block for varies applications,\r\nsuch as databases, biometrics, and machine learning.\r\nIn this work, we are interested in the private ANNS problem,\r\nwhere the client wants to learn (and can only learn) the ANNS\r\nresults without revealing the query to the server. Previous private\r\nANNS works either suffers from high communication\r\ncost (Chen et al., USENIX Security 2020) or works under\r\na weaker security assumption of two non-colluding servers\r\n(Servan-Schreiber et al., SP 2022). We present Panther, an\r\nefficient private ANNS framework under the single server\r\nsetting. Panther achieves its high performance via several\r\nnovel co-designs of private information retrieval (PIR), secretsharing,\r\ngarbled circuits, and homomorphic encryption. We\r\nmade extensive experiments using Panther on four public\r\ndatasets, results show that Panther could answer an ANNS\r\nquery on 10 million points in 23 seconds with 318 MB of\r\ncommunication. This is more than 6\u00d7 faster and 18\u00d7 more\r\ncompact than Chen et al..",
        "authors": [
            "Jingyu Li",
            "Zhicong Huang",
            "Min Zhang",
            "Jian Liu",
            "Cheng Hong",
            "Tao Wei",
            "Wenguang Chen"
        ],
        "category": "Applications",
        "lastmodified": "2024-10-31 02:44:41",
        "name": "2024/1774",
        "pdffile": "2024/1774.pdf",
        "pid": 1774,
        "title": "PANTHER: Private Approximate Nearest Neighbor Search in the Single Server Setting",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Adaptor signatures (AS) extend the functionality of traditional digital signatures by enabling the generation of a pre-signature tied to an instance of a hard NP relation, which can later be turned (adapted) into a full signature upon revealing a corresponding witness. The recent work by Liu et al. devised a generic AS scheme that can be used for any NP relation---which here we will refer to as universal adaptor signatures scheme, in short UAS---from any one-way function. However, this generic construction depends on the Karp reduction to the Hamiltonian cycle problem, which adds significant overhead and hinders practical applicability.\r\n\r\nIn this work, we present an alternative approach to construct universal adaptor signature schemes relying on the multi-party computation in the head (MPCitH) paradigm. This overcomes the reliance on the costly Karp reduction, while inheriting the core property of the MPCitH---which makes it an invaluable tool in efficient cryptographic protocols---namely, that the construction is black-box with respect to the underlying cryptographic primitive (while it remains non-black-box in the relation being proven). Our framework simplifies the design of UAS and enhances their applicability across a wide range of decentralized applications, such as blockchain and privacy-preserving systems. Our results demonstrate that MPCitH-based UAS schemes offer strong security guarantees while making them a promising tool in the design of real-world cryptographic protocols.",
        "authors": [
            "Michele Ciampi",
            "Xiangyu Liu",
            "Ioannis Tzannetos",
            "Vassilis Zikas"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-10-31 02:31:17",
        "name": "2024/1773",
        "pdffile": "2024/1773.pdf",
        "pid": 1773,
        "title": "Universal Adaptor Signatures from Blackbox Multi-Party Computation",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "ARADI is a low-latency block cipher proposed by the NSA (National Security Agency) in 2024 for memory encryption. Bellini et al. experimentally demonstrated that in specific cubes of 5-round ARADI, the cube sums are byte-wise equal, for example, to 0x9d9dc5c5. This paper modifies the MILP-based division property algorithm to prove this and observes that the rotation amount of 8 in ARADI causes cancellations of monomials, allowing us to extend the byte-wise equal property up to 8 rounds. As a result, we obtained distinguishers for rounds 6 and 7 with lower data complexities of $2^{77}$ and $2^{112}$, respectively, compared to previous methods.",
        "authors": [
            "Sunyeop Kim",
            "Insung Kim",
            "Dongjae Lee",
            "Deukjo Hong",
            "Jaechul Sung",
            "Seokhie Hong"
        ],
        "category": "Secret-key cryptography",
        "lastmodified": "2024-10-31 01:16:08",
        "name": "2024/1772",
        "pdffile": "2024/1772.pdf",
        "pid": 1772,
        "title": "Byte-wise equal property of ARADI",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "In the domain of algorithm substitution attacks (ASAs), we initiate work in a new direction, namely to consider such attacks on algorithms that are public, meaning contain no secret-key material. Examples are hash functions, and verification algorithms of signature schemes and non-interactive arguments.  In what we call a PA-SA (Public-Algorithm Substitution Attack), the big-brother adversary replaces the public algorithm $f$ with a subverted algorithm, while retaining a backdoor to the latter. We consider big-brother's goal for the PA-SA to be three-fold: it desires utility (it can break an $f$-using scheme or application), undetectability (outsiders can't detect the substitution) and exclusivity (nobody other than big-brother can exploit the substitution). We start with a general setting in which $f$ is arbitrary, giving strong definitions for the three goals, and then a construction of a PA-SA that we prove meets them. We use this to derive, as applications, PA-SAs on hash functions, signature verification and verification of non-interactive arguments, exhibiting new and effective ways to subvert these. As a further application of the first two, we give a PA-SA on X.509 TLS certificates. While ASAs have been traditionally confined to exfiltrating secret keys, our work shows that they are possible and effective at subverting public functions where there are no keys to exfiltrate. Our constructions serve to help defenders and developers identify potential attacks by illustrating how they might be built.",
        "authors": [
            "Mihir Bellare",
            "Doreen Riepel",
            "Laura Shea"
        ],
        "category": "Applications",
        "lastmodified": "2024-10-31 00:45:31",
        "name": "2024/536",
        "pdffile": "2024/536.pdf",
        "pid": 536,
        "title": "Public-Algorithm Substitution Attacks: Subverting Hashing and Verification",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We present a new compact and tightly secure (anonymous) identity-based encryption (IBE) scheme based on structured lattices. This is the first IBE scheme that is (asymptotically) as compact as the most practical NTRU-based schemes and tightly secure under the module learning with errors (MLWE) assumption, known as the standard lattice assumption, in the (quantum) random oracle model. In particular, our IBE scheme is the most compact lattice-based scheme (except for NTRU-based schemes). We design our IBE scheme by instantiating the framework of Gentry, Peikert, and Vaikuntanathan (STOC`08) using the compact trapdoor proposed by Yu, Jia, and Wang (CRYPTO'23). The tightness of our IBE scheme is achieved by extending the proof technique of Katsumata et al. (ASIACRYPT'18, JoC'21) to the hermit normal form setting. To achieve this, we developed some new results on module lattices that may be of independent interest.",
        "authors": [
            "Toi Tomita",
            "Junji Shikata"
        ],
        "category": "Public-key cryptography",
        "lastmodified": "2024-10-31 00:15:21",
        "name": "2024/1765",
        "pdffile": "2024/1765.pdf",
        "pid": 1765,
        "title": "Compact and Tightly Secure (Anonymous) IBE from Module LWE in the QROM",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "This note studies a method of committing to a polynomial in a way that allows executions of low degree tests such as FRI to be batched and even deferred. In particular, it achieves (unlimited-depth) aggregation for STARKs.",
        "authors": [
            "Alan Szepieniec"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-10-30 20:43:54",
        "name": "2024/1752",
        "pdffile": "2024/1752.pdf",
        "pid": 1752,
        "title": "DEEP Commitments and Their Applications",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "We construct somewhat homomorphic encryption schemes from the learning sparse parities with noise (sparse LPN) problem, along with an assumption that implies linearly homomorphic encryption (e.g., the decisional Diffie-Hellman or decisional composite residuosity assumptions). Our resulting schemes support an a-priori bounded number of homomorphic operations: $O(\\log \\lambda/\\log \\log \\lambda)$ multiplications followed by poly($\\lambda$) additions, where $\\lambda \\in \\mathbb{N}$ is a security parameter. These schemes have compact ciphertexts: after homomorphic evaluation, the bit-length of each ciphertext is a fixed polynomial in the security parameter $\\lambda$, independent of the number of homomorphic operations applied to it. This gives the first somewhat homomorphic encryption schemes that can evaluate the class of bounded-degree polynomials with a bounded number of monomials without relying on lattice assumptions or bilinear maps.\r\n\r\nMuch like in the Gentry-Sahai-Waters fully homomorphic encryption scheme, ciphertexts in our scheme are matrices, homomorphic addition is matrix addition, and homomorphic multiplication is matrix multiplication. Moreover, when encrypting many messages at once and performing many homomorphic evaluations at once, the bit-length of ciphertexts in some of our schemes (before and after homomorphic evaluation) can be arbitrarily close to the bit-length of the plaintexts. The main limitation of our schemes is that they require a large evaluation key, whose size scales with the complexity of the homomorphic computation performed, though this key can be re-used across any polynomial number of encryptions and evaluations.",
        "authors": [
            "Henry Corrigan-Gibbs",
            "Alexandra Henzinger",
            "Yael Kalai",
            "Vinod Vaikuntanathan"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-10-30 20:10:44",
        "name": "2024/1760",
        "pdffile": "2024/1760.pdf",
        "pid": 1760,
        "title": "Somewhat Homomorphic Encryption from Linear Homomorphism and Sparse LPN",
        "withdrawn": 0,
        "year": 2024
    },
    {
        "abstract": "Proving knowledge of a secret isogeny has recently been proposed as a means to generate supersingular elliptic curves of unknown endomorphism ring, but is equally important for cryptographic protocol design as well as for real world deployments. Recently, Cong, Lai and Levin (ACNS'23) have investigated the use of general-purpose (non-interactive) zero-knowledge proof systems for proving the knowledge of an isogeny of degree $2^k$ between supersingular elliptic curves. In particular, their approach is to model this relation via a sequence of $k$ successive steps of a walk in the supersingular isogeny graph and to show that the respective $j$-invariants are roots of the second modular polynomial. They then arithmetize this relation and show that this approach, when compared to state-of-the-art tailor-made proofs of knowledge by Basso et al. (EUROCRYPT'23), gives a 3-10$\\times$ improvement in proof and verification times, with comparable proof sizes. \r\n\r\n In this paper we ask whether we can further improve the modular polynomial-based approach and generalize its application to primes ${\\ell>2}$, as used in some recent isogeny-based constructions. We will answer these questions affirmatively, by designing efficient arithmetizations for each ${\\ell \\in \\{2, 3, 5, 7, 13\\}}$ that achieve an improvement over Cong, Lai and Levin of up to 48%.\r\n\r\n Our main technical tool and source of efficiency gains is to switch from classical modular polynomials to canonical modular polynomials. Adapting the well-known results on the former to the latter polynomials, however, is not straight-forward and requires some technical effort. We prove various interesting connections via novel use of resultant theory, and advance the understanding of canonical modular polynomials, which might be of independent interest.",
        "authors": [
            "Thomas den Hollander",
            "S\u00f6ren Kleine",
            "Marzio Mula",
            "Daniel Slamanig",
            "Sebastian A. Spindler"
        ],
        "category": "Cryptographic protocols",
        "lastmodified": "2024-10-30 18:21:49",
        "name": "2024/1738",
        "pdffile": "2024/1738.pdf",
        "pid": 1738,
        "title": "More Efficient Isogeny Proofs of Knowledge via Canonical Modular Polynomials",
        "withdrawn": 0,
        "year": 2024
    }
]